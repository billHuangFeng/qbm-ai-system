# è¾¹é™…å½±å“åˆ†æç³»ç»Ÿ - AI Copiloté›†æˆæ–‡æ¡£

## æ–‡æ¡£å…ƒæ•°æ®
- **ç‰ˆæœ¬**: v1.0.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-10-23
- **è´Ÿè´£äºº**: Cursor (ç®—æ³•è®¾è®¡ä¸æŠ€æœ¯æ¶æ„)
- **å®æ–½æ–¹**: Lovable (å‰ç«¯é›†æˆä¸UIå®ç°)
- **çŠ¶æ€**: â³ å¾…Lovableå®æ–½

---

## 1. ç³»ç»Ÿæ¦‚è¿°

### 1.1 ç›®æ ‡
ä¸ºè¾¹é™…å½±å“åˆ†æç³»ç»Ÿé›†æˆAI Copilotï¼Œæä¾›æ™ºèƒ½åŒ–çš„æ•°æ®æ´å¯Ÿã€å†³ç­–æ”¯æŒå’Œè‡ªç„¶è¯­è¨€äº¤äº’èƒ½åŠ›ï¼Œå¸®åŠ©ç”¨æˆ·ï¼š
- å¿«é€Ÿç†è§£å¤æ‚çš„è¾¹é™…å½±å“åˆ†æç»“æœ
- é€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®å’Œæ‰§è¡Œåˆ†æ
- è·å¾—æ™ºèƒ½åŒ–çš„ä¼˜åŒ–å»ºè®®å’Œå†³ç­–æ”¯æŒ
- è‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–

### 1.2 æ ¸å¿ƒä»·å€¼
1. **é™ä½ä½¿ç”¨é—¨æ§›**: é€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’ï¼Œè®©éæŠ€æœ¯ç”¨æˆ·ä¹Ÿèƒ½è½»æ¾ä½¿ç”¨ç³»ç»Ÿ
2. **æå‡åˆ†ææ•ˆç‡**: è‡ªåŠ¨åŒ–æ•°æ®æŸ¥è¯¢ã€åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆï¼ŒèŠ‚çœ80%çš„äººå·¥æ—¶é—´
3. **å¢å¼ºå†³ç­–è´¨é‡**: åŸºäºAIçš„æ´å¯Ÿå’Œå»ºè®®ï¼Œæä¾›æ›´å…¨é¢çš„å†³ç­–æ”¯æŒ
4. **çŸ¥è¯†æ²‰æ·€**: æ„å»ºä¼ä¸šä¸“å±çŸ¥è¯†åº“ï¼Œç§¯ç´¯æœ€ä½³å®è·µ

### 1.3 æŠ€æœ¯ç‰¹ç‚¹
- **æ··åˆéƒ¨ç½²**: Gemini APIå¤„ç†å¤æ‚æ¨ç† + æœ¬åœ°æ¨¡å‹å¤„ç†ç®€å•ä»»åŠ¡
- **åˆ†é˜¶æ®µå®ç°**: MVP 5ä¸ªå·¥å…· â†’ æ‰©å±•10ä¸ª â†’ å®Œæ•´15ä¸ª
- **æ™ºèƒ½è·¯ç”±**: æ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©å¤„ç†æ¨¡å¼
- **æˆæœ¬ä¼˜åŒ–**: ç¼“å­˜ç­–ç•¥ + æœ¬åœ°æ¨¡å‹ä¼˜å…ˆ + APIæŒ‰éœ€è°ƒç”¨

---

## 2. ç³»ç»Ÿæ¶æ„

### 2.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·ç•Œé¢å±‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ èŠå¤©ç•Œé¢  â”‚  â”‚ ä»ªè¡¨æ¿   â”‚  â”‚ æŠ¥å‘Šç”Ÿæˆ  â”‚  â”‚ APIè°ƒç”¨   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      æ™ºèƒ½è·¯ç”±å±‚ (Question Router)    â”‚
        â”‚  - é—®é¢˜å¤æ‚åº¦åˆ†æ                     â”‚
        â”‚  - æ¨¡å¼é€‰æ‹© (ç®€å•/æ·±åº¦/æ··åˆ)          â”‚
        â”‚  - è´Ÿè½½å‡è¡¡                          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                     â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ ç®€å•é—®ç­” â”‚                         â”‚ æ·±åº¦ç ”ç©¶  â”‚
   â”‚  æ¨¡å¼   â”‚                         â”‚   æ¨¡å¼   â”‚
   â”‚(æœ¬åœ°æ¨¡å‹)â”‚                         â”‚(Gemini API)â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Agent Loop (æ ¸å¿ƒå¼•æ“)         â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
        â”‚  â”‚ 1. é—®é¢˜ç†è§£ (Intent Parser) â”‚    â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â”‚             â–¼                       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
        â”‚  â”‚ 2. å·¥å…·è§„åˆ’ (Tool Planner)  â”‚    â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â”‚             â–¼                       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
        â”‚  â”‚ 3. æ‰§è¡Œè°ƒç”¨ (Tool Executor) â”‚    â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â”‚             â–¼                       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
        â”‚  â”‚ 4. ç»“æœåˆæˆ (Synthesizer)   â”‚    â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       Tool Server (å·¥å…·æœåŠ¡å±‚)       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”       â”‚
        â”‚  â”‚ æ•°æ®  â”‚ â”‚ åˆ†æ  â”‚ â”‚ å¤–éƒ¨  â”‚       â”‚
        â”‚  â”‚ æŸ¥è¯¢  â”‚ â”‚ æ‰§è¡Œ  â”‚ â”‚ é›†æˆ  â”‚       â”‚
        â”‚  â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜       â”‚
        â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚        â”‚        â”‚
        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         æ•°æ®ä¸æœåŠ¡å±‚                 â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
        â”‚  â”‚PostgreSQLâ”‚  â”‚  Redis   â”‚        â”‚
        â”‚  â”‚ (Supabase)â”‚  â”‚ (Cache)  â”‚        â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
        â”‚  â”‚ Backend  â”‚  â”‚ External â”‚        â”‚
        â”‚  â”‚   API    â”‚  â”‚   APIs   â”‚        â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ··åˆéƒ¨ç½²ç­–ç•¥

#### 2.2.1 æ¨¡å‹é€‰æ‹©çŸ©é˜µ

| ä»»åŠ¡ç±»å‹ | å¤æ‚åº¦ | æ¨¡å‹é€‰æ‹© | é¢„æœŸå“åº”æ—¶é—´ | æˆæœ¬/è¯·æ±‚ |
|---------|-------|---------|------------|----------|
| æ•°æ®æŸ¥è¯¢ | ä½ | æœ¬åœ°æ¨¡å‹ (Qwen2.5-7B) | <1ç§’ | $0 |
| ç®€å•åˆ†æ | ä½-ä¸­ | æœ¬åœ°æ¨¡å‹ | 1-3ç§’ | $0 |
| æŠ¥å‘Šç”Ÿæˆ | ä¸­ | æœ¬åœ°æ¨¡å‹ + ç¼“å­˜ | 3-10ç§’ | $0 |
| å¤æ‚æ¨ç† | é«˜ | Gemini 1.5 Pro | 5-15ç§’ | $0.001-0.005 |
| æ·±åº¦ç ”ç©¶ | æé«˜ | Gemini 1.5 Pro + Tools | 30-120ç§’ | $0.01-0.05 |

#### 2.2.2 æ™ºèƒ½è·¯ç”±è§„åˆ™

```python
# æ™ºèƒ½è·¯ç”±å†³ç­–æ ‘
def route_question(question: str, context: Dict) -> str:
    """
    æ ¹æ®é—®é¢˜ç‰¹å¾é€‰æ‹©å¤„ç†æ¨¡å¼
    
    è¿”å›å€¼:
        - "local_simple": æœ¬åœ°æ¨¡å‹å¤„ç†ç®€å•é—®é¢˜
        - "local_cached": ä½¿ç”¨ç¼“å­˜ç»“æœ
        - "gemini_complex": Gemini APIå¤„ç†å¤æ‚é—®é¢˜
        - "hybrid": æ··åˆæ¨¡å¼ï¼ˆå…ˆæœ¬åœ°ï¼Œå¿…è¦æ—¶å‡çº§åˆ°APIï¼‰
    """
    
    # 1. æ£€æŸ¥ç¼“å­˜
    if cache_hit(question):
        return "local_cached"
    
    # 2. é—®é¢˜ç‰¹å¾æå–
    features = extract_question_features(question)
    
    # 3. å¤æ‚åº¦è¯„åˆ† (0-10)
    complexity_score = calculate_complexity(features)
    
    # 4. è·¯ç”±å†³ç­–
    if complexity_score <= 3:
        # ç®€å•é—®é¢˜ï¼šæ•°æ®æŸ¥è¯¢ã€çŠ¶æ€æŸ¥çœ‹
        return "local_simple"
    elif complexity_score <= 7:
        # ä¸­ç­‰é—®é¢˜ï¼šå•æ¬¡åˆ†æã€æŠ¥å‘Šç”Ÿæˆ
        return "hybrid"  # å…ˆå°è¯•æœ¬åœ°ï¼Œå¤±è´¥åˆ™å‡çº§
    else:
        # å¤æ‚é—®é¢˜ï¼šå¤šæ­¥æ¨ç†ã€æ·±åº¦åˆ†æ
        return "gemini_complex"

def calculate_complexity(features: Dict) -> float:
    """
    è®¡ç®—é—®é¢˜å¤æ‚åº¦
    
    è€ƒè™‘å› ç´ :
        - æŸ¥è¯¢æ•°æ®é‡ (0-2åˆ†)
        - åˆ†ææ­¥éª¤æ•° (0-3åˆ†)
        - æ¨ç†æ·±åº¦ (0-3åˆ†)
        - æ—¶é—´èŒƒå›´ (0-1åˆ†)
        - å¤–éƒ¨ä¾èµ– (0-1åˆ†)
    """
    score = 0.0
    
    # æ•°æ®é‡è¯„åˆ†
    if features["data_volume"] == "single_record":
        score += 0
    elif features["data_volume"] == "small_query":
        score += 1
    else:
        score += 2
    
    # åˆ†ææ­¥éª¤è¯„åˆ†
    score += min(features["analysis_steps"], 3)
    
    # æ¨ç†æ·±åº¦è¯„åˆ†
    if "why" in features["question_type"] or "explain" in features["question_type"]:
        score += 2
    if "predict" in features["question_type"] or "optimize" in features["question_type"]:
        score += 1
    
    # æ—¶é—´èŒƒå›´è¯„åˆ†
    if features["time_range"] == "multi_period":
        score += 1
    
    # å¤–éƒ¨ä¾èµ–è¯„åˆ†
    if features["requires_external_data"]:
        score += 1
    
    return min(score, 10.0)
```

### 2.3 Agent Loopè®¾è®¡

#### 2.3.1 å››é˜¶æ®µå¤„ç†æµç¨‹

```python
class AIAgent:
    """AI Copilotæ ¸å¿ƒAgent"""
    
    def __init__(self, model_type: str = "hybrid"):
        self.model_type = model_type
        self.conversation_history = []
        self.tool_server = ToolServer()
        self.cache = RedisCache()
    
    async def process_query(self, user_query: str) -> AgentResponse:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„å®Œæ•´æµç¨‹
        """
        
        # é˜¶æ®µ1: é—®é¢˜ç†è§£
        intent = await self.parse_intent(user_query)
        
        # é˜¶æ®µ2: å·¥å…·è§„åˆ’
        plan = await self.plan_tools(intent)
        
        # é˜¶æ®µ3: æ‰§è¡Œè°ƒç”¨
        results = await self.execute_tools(plan)
        
        # é˜¶æ®µ4: ç»“æœåˆæˆ
        response = await self.synthesize_response(results, user_query)
        
        # æ›´æ–°å†å²
        self.conversation_history.append({
            "query": user_query,
            "intent": intent,
            "plan": plan,
            "results": results,
            "response": response
        })
        
        return response
    
    async def parse_intent(self, query: str) -> Intent:
        """
        é˜¶æ®µ1: é—®é¢˜ç†è§£
        
        æå–ç”¨æˆ·æ„å›¾ã€å®ä½“å’Œå‚æ•°
        """
        # ä½¿ç”¨æœ¬åœ°NLUæ¨¡å‹æˆ–ç®€å•è§„åˆ™
        intent_classifier = IntentClassifier()
        entity_extractor = EntityExtractor()
        
        intent_type = intent_classifier.predict(query)
        entities = entity_extractor.extract(query)
        
        return Intent(
            type=intent_type,  # "query_data", "execute_analysis", etc.
            entities=entities,  # {"asset": "ç ”å‘èµ„äº§", "month": "2024-10"}
            confidence=0.95,
            requires_clarification=False
        )
    
    async def plan_tools(self, intent: Intent) -> ToolPlan:
        """
        é˜¶æ®µ2: å·¥å…·è§„åˆ’
        
        æ ¹æ®æ„å›¾é€‰æ‹©åˆé€‚çš„å·¥å…·é“¾
        """
        if intent.type == "query_asset_data":
            return ToolPlan(
                steps=[
                    ToolCall(name="query_asset_data", params=intent.entities)
                ]
            )
        
        elif intent.type == "execute_marginal_analysis":
            return ToolPlan(
                steps=[
                    ToolCall(name="query_asset_data", params={"month": intent.entities["month"]}),
                    ToolCall(name="query_capability_data", params={"month": intent.entities["month"]}),
                    ToolCall(name="execute_marginal_analysis", params={
                        "asset_data": "$step_1_result",
                        "capability_data": "$step_2_result"
                    }),
                    ToolCall(name="get_insights", params={"analysis_result": "$step_3_result"})
                ]
            )
        
        elif intent.type == "generate_report":
            return ToolPlan(
                steps=[
                    ToolCall(name="query_analysis_results", params=intent.entities),
                    ToolCall(name="generate_report", params={
                        "data": "$step_1_result",
                        "format": "pdf"
                    })
                ]
            )
        
        else:
            # å¯¹äºæœªçŸ¥æ„å›¾ï¼Œä½¿ç”¨LLMåŠ¨æ€è§„åˆ’
            return await self.llm_plan_tools(intent)
    
    async def execute_tools(self, plan: ToolPlan) -> List[ToolResult]:
        """
        é˜¶æ®µ3: æ‰§è¡Œè°ƒç”¨
        
        æŒ‰é¡ºåºæ‰§è¡Œå·¥å…·é“¾ï¼Œå¤„ç†ä¾èµ–å’Œé”™è¯¯
        """
        results = []
        context = {}
        
        for step in plan.steps:
            try:
                # è§£æå‚æ•°ä¸­çš„å˜é‡å¼•ç”¨ ($step_N_result)
                resolved_params = self.resolve_params(step.params, context)
                
                # æ£€æŸ¥ç¼“å­˜
                cache_key = f"{step.name}:{resolved_params}"
                cached_result = await self.cache.get(cache_key)
                
                if cached_result:
                    result = cached_result
                else:
                    # è°ƒç”¨å·¥å…·
                    result = await self.tool_server.call(step.name, resolved_params)
                    
                    # ç¼“å­˜ç»“æœ
                    await self.cache.set(cache_key, result, ttl=3600)
                
                results.append(result)
                context[f"step_{len(results)}_result"] = result.data
                
            except Exception as e:
                # é”™è¯¯å¤„ç†å’Œé‡è¯•
                if step.retry_on_error:
                    result = await self.retry_tool_call(step, resolved_params)
                    results.append(result)
                else:
                    results.append(ToolResult(
                        success=False,
                        error=str(e),
                        data=None
                    ))
        
        return results
    
    async def synthesize_response(self, results: List[ToolResult], 
                                  original_query: str) -> AgentResponse:
        """
        é˜¶æ®µ4: ç»“æœåˆæˆ
        
        å°†å·¥å…·æ‰§è¡Œç»“æœåˆæˆè‡ªç„¶è¯­è¨€å“åº”
        """
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸ
        all_success = all(r.success for r in results)
        
        if not all_success:
            return AgentResponse(
                success=False,
                message="æŠ±æ­‰ï¼Œæ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚",
                data=None,
                suggestions=["è¯·æ£€æŸ¥è¾“å…¥å‚æ•°æ˜¯å¦æ­£ç¡®", "ç¨åå†è¯•"]
            )
        
        # ä½¿ç”¨LLMåˆæˆå“åº”ï¼ˆæœ¬åœ°æ¨¡å‹æˆ–Geminiï¼‰
        if self.model_type == "local" or len(results) == 1:
            # ç®€å•æƒ…å†µï¼šä½¿ç”¨æ¨¡æ¿
            response_text = self.template_response(results, original_query)
        else:
            # å¤æ‚æƒ…å†µï¼šä½¿ç”¨LLM
            response_text = await self.llm_synthesize(results, original_query)
        
        return AgentResponse(
            success=True,
            message=response_text,
            data=[r.data for r in results],
            suggestions=self.generate_suggestions(results)
        )
```

---

## 3. å·¥å…·å‡½æ•°å®šä¹‰ï¼ˆåˆ†ä¸‰é˜¶æ®µå®ç°ï¼‰

### 3.1 MVPé˜¶æ®µï¼ˆ5ä¸ªæ ¸å¿ƒå·¥å…·ï¼‰

å®æ–½ä¼˜å…ˆçº§ï¼šâ­â­â­â­â­ (æœ€é«˜ä¼˜å…ˆçº§)

#### 3.1.1 query_analysis_results

**åŠŸèƒ½**: æŸ¥è¯¢å†å²åˆ†æç»“æœ

**è¾“å…¥å‚æ•°**:
```python
{
    "tenant_id": str,  # ç§Ÿæˆ·ID (ä»è®¤è¯Tokenè·å–)
    "analysis_type": str,  # åˆ†æç±»å‹: "marginal_impact", "weight_optimization", etc.
    "time_range": {
        "start_month": str,  # "2024-01"
        "end_month": str     # "2024-10"
    },
    "filters": {  # å¯é€‰è¿‡æ»¤æ¡ä»¶
        "asset_type": str,  # "ç ”å‘èµ„äº§", "ç”Ÿäº§èµ„äº§", etc.
        "capability_type": str,
        "min_impact_score": float
    },
    "sort_by": str,  # "date", "impact_score", "r2_score"
    "limit": int  # è¿”å›ç»“æœæ•°é‡é™åˆ¶
}
```

**è¾“å‡ºæ ¼å¼**:
```python
{
    "success": bool,
    "data": [
        {
            "analysis_id": str,
            "analysis_type": str,
            "created_at": str,
            "parameters": dict,
            "results": {
                "impact_scores": dict,
                "r2_score": float,
                "insights": list
            },
            "summary": str
        }
    ],
    "total_count": int,
    "execution_time_ms": int
}
```

**APIå®ç°**:
```python
# backend/src/api/endpoints/ai_copilot.py
@router.post("/tools/query_analysis_results")
async def query_analysis_results(
    params: QueryAnalysisParams,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æŸ¥è¯¢å†å²åˆ†æç»“æœ"""
    
    # æ„å»ºæŸ¥è¯¢
    query = db.query(AnalysisResult).filter(
        AnalysisResult.tenant_id == current_user.tenant_id,
        AnalysisResult.analysis_type == params.analysis_type
    )
    
    # åº”ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
    if params.time_range:
        query = query.filter(
            AnalysisResult.analysis_month >= params.time_range.start_month,
            AnalysisResult.analysis_month <= params.time_range.end_month
        )
    
    # åº”ç”¨å…¶ä»–è¿‡æ»¤æ¡ä»¶
    if params.filters:
        if params.filters.asset_type:
            query = query.filter(AnalysisResult.asset_type == params.filters.asset_type)
    
    # æ’åºå’Œé™åˆ¶
    query = query.order_by(getattr(AnalysisResult, params.sort_by).desc())
    query = query.limit(params.limit)
    
    results = query.all()
    
    return {
        "success": True,
        "data": [serialize_analysis_result(r) for r in results],
        "total_count": len(results)
    }
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
# Agentè°ƒç”¨ç¤ºä¾‹
result = await tool_server.call("query_analysis_results", {
    "tenant_id": "enterprise_001",
    "analysis_type": "marginal_impact",
    "time_range": {
        "start_month": "2024-01",
        "end_month": "2024-10"
    },
    "limit": 10
})

# è¿”å›: æœ€è¿‘10æ¬¡è¾¹é™…å½±å“åˆ†æç»“æœ
```

#### 3.1.2 execute_marginal_analysis

**åŠŸèƒ½**: æ‰§è¡Œè¾¹é™…å½±å“åˆ†æ

**è¾“å…¥å‚æ•°**:
```python
{
    "tenant_id": str,
    "analysis_month": str,  # "2024-10"
    "analysis_scope": {
        "assets": list,  # ["ç ”å‘èµ„äº§", "ç”Ÿäº§èµ„äº§"] æˆ– "all"
        "capabilities": list,  # ["ç ”å‘èƒ½åŠ›", "ç”Ÿäº§èƒ½åŠ›"] æˆ– "all"
        "value_types": list  # ["äº§å“å†…åœ¨ä»·å€¼", "å®¢æˆ·è®¤çŸ¥ä»·å€¼"] æˆ– "all"
    },
    "options": {
        "use_historical_fitting": bool,  # æ˜¯å¦ä½¿ç”¨å†å²æ•°æ®æ‹Ÿåˆ
        "optimize_weights": bool,  # æ˜¯å¦ä¼˜åŒ–æƒé‡
        "generate_insights": bool  # æ˜¯å¦ç”Ÿæˆæ´å¯Ÿ
    }
}
```

**è¾“å‡ºæ ¼å¼**:
```python
{
    "success": bool,
    "analysis_id": str,
    "results": {
        "delta_formulas": {
            "èµ„äº§è¾¹é™…å½±å“": {
                "ç ”å‘èµ„äº§": {
                    "current_value": float,
                    "delta": float,
                    "npv_contribution": float
                },
                // ...å…¶ä»–èµ„äº§
            },
            "èƒ½åŠ›è¾¹é™…å½±å“": {
                "ç ”å‘èƒ½åŠ›": {
                    "current_value": float,
                    "delta": float,
                    "stable_outcome_score": float
                },
                // ...å…¶ä»–èƒ½åŠ›
            },
            "æ•ˆèƒ½æŒ‡æ ‡": {
                "ç ”å‘æ•ˆèƒ½": {
                    "value": float,
                    "formula": "äº§å“ç‰¹æ€§ä¼°å€¼ Ã· (â–³ç ”å‘èƒ½åŠ›Ã—a2 + â–³ç ”å‘èµ„äº§Ã—b2)",
                    "interpretation": "ç ”å‘æŠ•å…¥äº§å‡ºæ¯”æå‡15%"
                },
                // ...å…¶ä»–æ•ˆèƒ½
            },
            "ä»·å€¼è¯„ä¼°": {
                "äº§å“å†…åœ¨ä»·å€¼": {
                    "value": float,
                    "delta": float,
                    "wtp_score": float
                },
                // ...å…¶ä»–ä»·å€¼
            },
            "æ”¶å…¥å½±å“": {
                "é¦–å•æ”¶å…¥": float,
                "å¤è´­æ”¶å…¥": float,
                "è¿½é”€æ”¶å…¥": float,
                "æ€»æ”¶å…¥": float
            },
            "åˆ©æ¶¦ä¸ROI": {
                "ç»è¥åˆ©æ¶¦": float,
                "å‡€åˆ©æ¶¦": float,
                "ROI": float,
                "reinvestment_suggestion": dict
            }
        },
        "model_performance": {
            "r2_score": float,
            "mse": float,
            "feature_importance": dict
        },
        "insights": [
            {
                "type": "opportunity",  # "opportunity", "risk", "recommendation"
                "title": str,
                "description": str,
                "priority": str,  # "high", "medium", "low"
                "action_items": list
            }
        ]
    },
    "execution_time_ms": int
}
```

**APIå®ç°**: 
```python
@router.post("/tools/execute_marginal_analysis")
async def execute_marginal_analysis(
    params: ExecuteAnalysisParams,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æ‰§è¡Œè¾¹é™…å½±å“åˆ†æ"""
    
    # 1. è·å–è¾“å…¥æ•°æ®
    asset_data = await get_asset_data(params.tenant_id, params.analysis_month)
    capability_data = await get_capability_data(params.tenant_id, params.analysis_month)
    value_data = await get_value_data(params.tenant_id, params.analysis_month)
    
    # 2. æ‰§è¡Œåˆ†æ
    algorithm_service = AlgorithmService()
    
    if params.options.use_historical_fitting:
        # ä½¿ç”¨å†å²æ•°æ®æ‹Ÿåˆä¼˜åŒ–
        historical_data = await get_historical_data(params.tenant_id, months=12)
        results = await algorithm_service.analyze_with_fitting(
            asset_data, capability_data, value_data, historical_data
        )
    else:
        # ä½¿ç”¨å›ºå®šå…¬å¼è®¡ç®—
        results = await algorithm_service.analyze_with_formulas(
            asset_data, capability_data, value_data
        )
    
    # 3. ç”Ÿæˆæ´å¯Ÿ
    if params.options.generate_insights:
        insights = await algorithm_service.generate_insights(results)
        results["insights"] = insights
    
    # 4. ä¿å­˜ç»“æœ
    analysis_record = AnalysisResult(
        tenant_id=params.tenant_id,
        analysis_type="marginal_impact",
        analysis_month=params.analysis_month,
        parameters=params.dict(),
        results=results,
        created_by=current_user.id
    )
    db.add(analysis_record)
    db.commit()
    
    return {
        "success": True,
        "analysis_id": analysis_record.id,
        "results": results
    }
```

#### 3.1.3 optimize_weights

**åŠŸèƒ½**: ä¼˜åŒ–æƒé‡å‚æ•°ï¼ˆa1-a6, b1-b6ï¼‰

**è¾“å…¥å‚æ•°**:
```python
{
    "tenant_id": str,
    "optimization_scope": str,  # "all", "efficiency", "specific"
    "target_weights": list,  # ["a1", "a2", "b1", ...] æˆ– "all"
    "historical_months": int,  # ä½¿ç”¨å¤šå°‘ä¸ªæœˆçš„å†å²æ•°æ®ï¼Œé»˜è®¤12
    "optimization_method": str,  # "grid_search", "bayesian", "genetic"
    "constraints": {
        "weight_sum": float,  # æƒé‡å’Œçº¦æŸï¼Œå¦‚ a1+a2+...+a6=1.0
        "weight_bounds": dict  # {"a1": [0.0, 1.0], ...}
    },
    "objective": str  # "maximize_r2", "minimize_mse", "maximize_profit_roi"
}
```

**è¾“å‡ºæ ¼å¼**:
```python
{
    "success": bool,
    "optimized_weights": {
        "a1": float,  # äº§å“è®¾è®¡èƒ½åŠ›æƒé‡
        "a2": float,  # ç ”å‘èƒ½åŠ›æƒé‡
        // ...
        "b1": float,  # äº§å“è®¾è®¡èµ„äº§æƒé‡
        "b2": float,  # ç ”å‘èµ„äº§æƒé‡
        // ...
    },
    "performance": {
        "before": {
            "r2_score": float,
            "mse": float,
            "profit_roi": float
        },
        "after": {
            "r2_score": float,
            "mse": float,
            "profit_roi": float
        },
        "improvement_pct": float
    },
    "validation_results": {
        "cross_validation_score": float,
        "stability_score": float,
        "confidence_level": float
    },
    "recommendations": [
        {
            "weight_name": str,
            "old_value": float,
            "new_value": float,
            "rationale": str
        }
    ]
}
```

**APIå®ç°**:
```python
@router.post("/tools/optimize_weights")
async def optimize_weights(
    params: OptimizeWeightsParams,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ä¼˜åŒ–æƒé‡å‚æ•°"""
    
    # 1. è·å–å†å²æ•°æ®
    historical_data = await get_historical_data(
        params.tenant_id, 
        months=params.historical_months
    )
    
    # 2. æ‰§è¡Œæƒé‡ä¼˜åŒ–
    algorithm_service = AlgorithmService()
    optimization_results = await algorithm_service.optimize_weights(
        data=historical_data,
        method=params.optimization_method,
        constraints=params.constraints,
        objective=params.objective
    )
    
    # 3. éªŒè¯ä¼˜åŒ–ç»“æœ
    validation_results = await algorithm_service.validate_weights(
        optimized_weights=optimization_results["optimized_weights"],
        test_data=historical_data[-3:]  # ä½¿ç”¨æœ€è¿‘3ä¸ªæœˆä½œä¸ºéªŒè¯é›†
    )
    
    # 4. ä¿å­˜ä¼˜åŒ–è®°å½•
    optimization_record = WeightOptimizationRecord(
        tenant_id=params.tenant_id,
        optimization_date=datetime.now(),
        parameters=params.dict(),
        results=optimization_results,
        validation=validation_results,
        created_by=current_user.id
    )
    db.add(optimization_record)
    db.commit()
    
    return {
        "success": True,
        "optimized_weights": optimization_results["optimized_weights"],
        "performance": optimization_results["performance"],
        "validation_results": validation_results
    }
```

#### 3.1.4 get_insights

**åŠŸèƒ½**: è·å–æ™ºèƒ½åˆ†ææ´å¯Ÿ

**è¾“å…¥å‚æ•°**:
```python
{
    "tenant_id": str,
    "analysis_id": str,  # å¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åŸºäºç‰¹å®šåˆ†æç”Ÿæˆæ´å¯Ÿ
    "insight_types": list,  # ["opportunity", "risk", "trend", "benchmark", "recommendation"]
    "time_range": {
        "start_month": str,
        "end_month": str
    },
    "focus_areas": list  # ["assets", "capabilities", "efficiency", "value", "revenue"]
}
```

**è¾“å‡ºæ ¼å¼**:
```python
{
    "success": bool,
    "insights": [
        {
            "id": str,
            "type": str,  # "opportunity", "risk", "trend", "benchmark", "recommendation"
            "category": str,  # "assets", "capabilities", etc.
            "priority": str,  # "high", "medium", "low"
            "title": str,
            "description": str,
            "evidence": {
                "data_points": list,
                "trend_analysis": dict,
                "comparison": dict
            },
            "impact_assessment": {
                "revenue_impact": str,  # "Â±Xä¸‡å…ƒ"
                "efficiency_impact": str,  # "Â±X%"
                "confidence": float  # 0-1
            },
            "action_items": [
                {
                    "action": str,
                    "expected_outcome": str,
                    "effort": str,  # "low", "medium", "high"
                    "timeline": str  # "1-2å‘¨", "1-3æœˆ"
                }
            ],
            "created_at": str
        }
    ],
    "summary": {
        "total_insights": int,
        "by_type": dict,
        "by_priority": dict,
        "key_findings": list
    }
}
```

**APIå®ç°**:
```python
@router.post("/tools/get_insights")
async def get_insights(
    params: GetInsightsParams,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–æ™ºèƒ½åˆ†ææ´å¯Ÿ"""
    
    # 1. è·å–åˆ†ææ•°æ®
    if params.analysis_id:
        analysis_data = db.query(AnalysisResult).filter(
            AnalysisResult.id == params.analysis_id
        ).first()
    else:
        # è·å–æ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰åˆ†æ
        analysis_data = db.query(AnalysisResult).filter(
            AnalysisResult.tenant_id == params.tenant_id,
            AnalysisResult.analysis_month >= params.time_range.start_month,
            AnalysisResult.analysis_month <= params.time_range.end_month
        ).all()
    
    # 2. ç”Ÿæˆæ´å¯Ÿ
    algorithm_service = AlgorithmService()
    insights = await algorithm_service.generate_insights(
        analysis_data=analysis_data,
        insight_types=params.insight_types,
        focus_areas=params.focus_areas
    )
    
    # 3. æ’åºå’Œè¿‡æ»¤
    insights = sorted(insights, key=lambda x: (
        {"high": 0, "medium": 1, "low": 2}[x["priority"]],
        -x["impact_assessment"]["confidence"]
    ))
    
    return {
        "success": True,
        "insights": insights,
        "summary": {
            "total_insights": len(insights),
            "by_type": count_by_field(insights, "type"),
            "by_priority": count_by_field(insights, "priority")
        }
    }
```

#### 3.1.5 search_knowledge_base

**åŠŸèƒ½**: æœç´¢å†…éƒ¨çŸ¥è¯†åº“

**è¾“å…¥å‚æ•°**:
```python
{
    "tenant_id": str,
    "query": str,  # è‡ªç„¶è¯­è¨€æŸ¥è¯¢
    "search_scope": list,  # ["formulas", "best_practices", "historical_analyses", "documentation"]
    "filters": {
        "date_range": dict,
        "relevance_threshold": float  # 0-1, æœ€ä½ç›¸å…³æ€§é˜ˆå€¼
    },
    "max_results": int,  # é»˜è®¤10
    "include_similar": bool  # æ˜¯å¦åŒ…å«ç›¸ä¼¼é—®é¢˜
}
```

**è¾“å‡ºæ ¼å¼**:
```python
{
    "success": bool,
    "results": [
        {
            "id": str,
            "type": str,  # "formula", "best_practice", "analysis", "doc"
            "title": str,
            "content": str,
            "relevance_score": float,  # 0-1
            "metadata": {
                "created_at": str,
                "updated_at": str,
                "author": str,
                "tags": list,
                "category": str
            },
            "related_items": list  # ç›¸å…³å†…å®¹IDåˆ—è¡¨
        }
    ],
    "suggested_queries": list,  # æ¨èçš„ç›¸å…³æœç´¢
    "total_results": int
}
```

**APIå®ç°**:
```python
@router.post("/tools/search_knowledge_base")
async def search_knowledge_base(
    params: SearchKnowledgeBaseParams,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æœç´¢å†…éƒ¨çŸ¥è¯†åº“"""
    
    # 1. å‘é‡åŒ–æŸ¥è¯¢
    embedding_service = EmbeddingService()
    query_vector = await embedding_service.embed(params.query)
    
    # 2. å‘é‡æœç´¢
    search_results = await vector_search(
        query_vector=query_vector,
        collection=f"knowledge_base_{params.tenant_id}",
        filters=params.filters,
        limit=params.max_results
    )
    
    # 3. è¿‡æ»¤å’Œæ’åº
    filtered_results = [
        r for r in search_results 
        if r["relevance_score"] >= params.filters.relevance_threshold
    ]
    
    # 4. è·å–ç›¸å…³å†…å®¹
    if params.include_similar:
        for result in filtered_results:
            result["related_items"] = await get_related_items(result["id"])
    
    # 5. ç”Ÿæˆæ¨èæŸ¥è¯¢
    suggested_queries = await generate_suggested_queries(
        params.query, filtered_results
    )
    
    return {
        "success": True,
        "results": filtered_results,
        "suggested_queries": suggested_queries,
        "total_results": len(filtered_results)
    }
```

### 3.2 æ‰©å±•é˜¶æ®µï¼ˆæ–°å¢5ä¸ªå·¥å…·ï¼Œå…±10ä¸ªï¼‰

å®æ–½ä¼˜å…ˆçº§ï¼šâ­â­â­â­ (é«˜ä¼˜å…ˆçº§)

#### 3.2.1 query_asset_data

**åŠŸèƒ½**: æŸ¥è¯¢æ ¸å¿ƒèµ„äº§æ•°æ®

**è¾“å…¥å‚æ•°**:
```python
{
    "tenant_id": str,
    "asset_types": list,  # ["ç ”å‘èµ„äº§", "äº§å“è®¾è®¡èµ„äº§", ...] æˆ– "all"
    "time_range": {
        "start_month": str,
        "end_month": str
    },
    "include_metrics": list,  # ["npv", "cash_flow", "roi", "trends"]
    "aggregation": str  # "monthly", "quarterly", "yearly", "total"
}
```

**è¾“å‡ºæ ¼å¼**: ç•¥ï¼ˆè¯¦è§å®Œæ•´æ–‡æ¡£ï¼‰

#### 3.2.2 query_capability_data

**åŠŸèƒ½**: æŸ¥è¯¢æ ¸å¿ƒèƒ½åŠ›æ•°æ®

#### 3.2.3 predict_trend

**åŠŸèƒ½**: è¶‹åŠ¿é¢„æµ‹ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰

#### 3.2.4 compare_benchmarks

**åŠŸèƒ½**: è¡Œä¸šåŸºå‡†å¯¹æ¯”

#### 3.2.5 generate_report

**åŠŸèƒ½**: ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆPDF/Excel/PPTï¼‰

### 3.3 å®Œæ•´é˜¶æ®µï¼ˆæ–°å¢5ä¸ªå·¥å…·ï¼Œå…±15ä¸ªï¼‰

å®æ–½ä¼˜å…ˆçº§ï¼šâ­â­â­ (ä¸­ç­‰ä¼˜å…ˆçº§ï¼Œæ‰©å±•åŠŸèƒ½ï¼‰

#### 3.3.1 search_industry_data

**åŠŸèƒ½**: å¤–éƒ¨è¡Œä¸šæ•°æ®æœç´¢ï¼ˆSerper APIï¼‰

#### 3.3.2 read_research_report

**åŠŸèƒ½**: è¯»å–ç ”ç©¶æŠ¥å‘Šï¼ˆJina APIï¼‰

#### 3.3.3 analyze_correlation

**åŠŸèƒ½**: ç›¸å…³æ€§åˆ†æ

#### 3.3.4 simulate_scenario

**åŠŸèƒ½**: åœºæ™¯æ¨¡æ‹Ÿ

#### 3.3.5 recommend_optimization

**åŠŸèƒ½**: ä¼˜åŒ–å»ºè®®æ¨è

---

## 4. Agentäº¤äº’æ¨¡å¼

### 4.1 ç®€å•é—®ç­”æ¨¡å¼

**é€‚ç”¨åœºæ™¯**: æ•°æ®æŸ¥è¯¢ã€çŠ¶æ€æŸ¥çœ‹ã€ç®€å•è®¡ç®—

**ç‰¹ç‚¹**:
- å•è½®å¯¹è¯
- å“åº”æ—¶é—´ < 30ç§’
- ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (Qwen2.5-7B)
- ç¼“å­˜å‹å¥½

**ç¤ºä¾‹å¯¹è¯**:
```
ç”¨æˆ·: å¸®æˆ‘æŸ¥ä¸€ä¸‹2024å¹´10æœˆçš„ç ”å‘èµ„äº§NPV
Agent: [è°ƒç”¨ query_asset_data]
      
      2024å¹´10æœˆç ”å‘èµ„äº§NPVæ•°æ®å¦‚ä¸‹ï¼š
      
      - ç ”å‘èµ„äº§æ€»å€¼ï¼š500ä¸‡å…ƒ
      - æœªæ¥5å¹´ç°é‡‘æµç°å€¼ï¼š620ä¸‡å…ƒ
      - NPVï¼š120ä¸‡å…ƒ
      - æœˆåº¦å¢é‡ï¼š+15ä¸‡å…ƒï¼ˆè¾ƒ9æœˆï¼‰
      
      ğŸ“Š è¶‹åŠ¿åˆ†æï¼šç ”å‘èµ„äº§NPVè¿ç»­3ä¸ªæœˆæ­£å¢é•¿ï¼Œä¸»è¦è´¡çŒ®æ¥è‡ª
      æ–°äº§å“ç ”å‘æŠ•å…¥çš„é¢„æœŸæ”¶ç›Šæå‡ã€‚
```

### 4.2 æ·±åº¦ç ”ç©¶æ¨¡å¼

**é€‚ç”¨åœºæ™¯**: å¤æ‚åˆ†æã€å¤šæ­¥æ¨ç†ã€æˆ˜ç•¥å†³ç­–

**ç‰¹ç‚¹**:
- å¤šè½®å¯¹è¯
- å“åº”æ—¶é—´ 2-5åˆ†é’Ÿ
- ä½¿ç”¨Gemini 1.5 Pro + å¤šå·¥å…·é“¾
- æ·±åº¦æ¨ç†å’Œæ´å¯Ÿ

**ç¤ºä¾‹å¯¹è¯**:
```
ç”¨æˆ·: æˆ‘æƒ³äº†è§£å¦‚ä½•ä¼˜åŒ–ç ”å‘æ•ˆèƒ½ä»¥æå‡æ•´ä½“åˆ©æ¶¦ç‡

Agent: [æ·±åº¦ç ”ç©¶æ¨¡å¼å·²å¯åŠ¨]
      
      æˆ‘å°†ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦ä¸ºæ‚¨è¿›è¡Œæ·±åº¦åˆ†æï¼š
      
      1. ğŸ“Š å½“å‰ç ”å‘æ•ˆèƒ½ç°çŠ¶è¯„ä¼°
      2. ğŸ” å†å²è¶‹åŠ¿å’Œæ¨¡å¼è¯†åˆ«
      3. âš–ï¸ è¡Œä¸šåŸºå‡†å¯¹æ¯”
      4. ğŸ’¡ ä¼˜åŒ–æœºä¼šè¯†åˆ«
      5. ğŸ¯ å…·ä½“è¡ŒåŠ¨å»ºè®®
      
      [æ‰§è¡Œå·¥å…·é“¾...]
      
      ### 1. å½“å‰ç ”å‘æ•ˆèƒ½ç°çŠ¶
      [è°ƒç”¨ execute_marginal_analysis, query_capability_data]
      
      æ‚¨çš„ç ”å‘æ•ˆèƒ½å½“å‰ä¸º 1.25 (äº§å“ç‰¹æ€§ä¼°å€¼ / ç ”å‘æŠ•å…¥)
      - é«˜äºè¡Œä¸šå¹³å‡æ°´å¹³ (1.08) 16%
      - ä½†ä½äºè¡Œä¸šé¢†å…ˆæ°´å¹³ (1.45) 14%
      
      ### 2. å†å²è¶‹åŠ¿åˆ†æ
      [è°ƒç”¨ predict_trend, analyze_correlation]
      
      è¿‡å»12ä¸ªæœˆç ”å‘æ•ˆèƒ½å‘ˆç°ä»¥ä¸‹ç‰¹å¾ï¼š
      - æ³¢åŠ¨è¾ƒå¤§ï¼ˆæ ‡å‡†å·®0.18ï¼‰ï¼Œè¯´æ˜ç¨³å®šæ€§ä¸è¶³
      - ä¸ç ”å‘èµ„äº§æŠ•å…¥ç›¸å…³æ€§ä¸º0.72ï¼Œå¼ºæ­£ç›¸å…³
      - ä¸ç ”å‘èƒ½åŠ›æå‡ç›¸å…³æ€§ä»…0.48ï¼Œå¼±ç›¸å…³
      
      ğŸ” å…³é”®å‘ç°ï¼šæ‚¨çš„ç ”å‘æ•ˆèƒ½ä¸»è¦ä¾èµ–èµ„äº§æŠ•å…¥ï¼Œè€Œéèƒ½åŠ›
      æå‡ï¼Œè¿™å¯èƒ½å¯¼è‡´è¾¹é™…æ•ˆç›Šé€’å‡ã€‚
      
      ### 3. è¡Œä¸šåŸºå‡†å¯¹æ¯”
      [è°ƒç”¨ compare_benchmarks, search_industry_data]
      
      å¯¹æ¯”è¡Œä¸šTOP 10ä¼ä¸šï¼š
      - ç ”å‘èµ„äº§æŠ•å…¥å æ¯”ï¼šæ‚¨ 12% vs è¡Œä¸šå‡å€¼ 15%
      - ç ”å‘èƒ½åŠ›å¾—åˆ†ï¼šæ‚¨ 75åˆ† vs è¡Œä¸šå‡å€¼ 82åˆ†
      - ç ”å‘æ•ˆèƒ½ï¼šæ‚¨ 1.25 vs è¡Œä¸šå‡å€¼ 1.08
      
      ğŸ’¡ æ´å¯Ÿï¼šæ‚¨çš„ç ”å‘æ•ˆèƒ½è™½é«˜äºå¹³å‡ï¼Œä½†æŠ•å…¥ä¸è¶³å¯èƒ½é™åˆ¶
      é•¿æœŸå¢é•¿æ½œåŠ›ã€‚
      
      ### 4. ä¼˜åŒ–æœºä¼šè¯†åˆ«
      [è°ƒç”¨ get_insights, analyze_correlation]
      
      è¯†åˆ«åˆ°3ä¸ªé«˜ä¼˜å…ˆçº§ä¼˜åŒ–æœºä¼šï¼š
      
      â­ æœºä¼š1ï¼šæå‡éœ€æ±‚æ´å¯Ÿå‡†ç¡®ç‡
      - å½“å‰ï¼š68% â†’ ç›®æ ‡ï¼š85%
      - é¢„æœŸæ”¶ç›Šï¼šç ”å‘æ•ˆèƒ½æå‡15-20%
      - æŠ•å…¥ï¼šéœ€æ±‚åˆ†æèƒ½åŠ›åŸ¹è®­ + å·¥å…·ä¼˜åŒ–
      
      â­ æœºä¼š2ï¼šä¼˜åŒ–äº§å“ç‰¹æ€§å¼€å‘ä¼˜å…ˆçº§
      - å½“å‰ï¼šæ— ç³»ç»ŸåŒ–æ’åº â†’ ç›®æ ‡ï¼šåŸºäºä»·å€¼æ’åº
      - é¢„æœŸæ”¶ç›Šï¼šé¿å…30%çš„æ— æ•ˆç ”å‘æŠ•å…¥
      - æŠ•å…¥ï¼šå»ºç«‹ç‰¹æ€§ä»·å€¼è¯„ä¼°ä½“ç³»
      
      â­ æœºä¼š3ï¼šå¢åŠ ç ”å‘èµ„äº§æŠ•å…¥
      - å½“å‰ï¼š500ä¸‡/æœˆ â†’ å»ºè®®ï¼š650ä¸‡/æœˆ (+30%)
      - é¢„æœŸæ”¶ç›Šï¼šNPVå¢é•¿45%ï¼ŒROIæå‡è‡³1.82
      - æŠ•å…¥ï¼šè´¢åŠ¡é‡æ–°é…ç½®
      
      ### 5. å…·ä½“è¡ŒåŠ¨å»ºè®®
      [è°ƒç”¨ recommend_optimization, simulate_scenario]
      
      **ä¼˜å…ˆçº§æ’åº**ï¼ˆåŸºäºROIå’Œå®æ–½éš¾åº¦ï¼‰ï¼š
      
      1ï¸âƒ£ ç«‹å³æ‰§è¡Œï¼ˆ1-2å‘¨ï¼‰ï¼š
         - å»ºç«‹äº§å“ç‰¹æ€§ä»·å€¼è¯„ä¼°æœºåˆ¶
         - æ¢³ç†å½“å‰åœ¨ç ”é¡¹ç›®ä¼˜å…ˆçº§
         - é¢„æœŸå¿«é€Ÿææ•ˆ10%
      
      2ï¸âƒ£ çŸ­æœŸæ‰§è¡Œï¼ˆ1-3æœˆï¼‰ï¼š
         - ç»„ç»‡éœ€æ±‚æ´å¯Ÿèƒ½åŠ›åŸ¹è®­
         - å¼•å…¥å®¢æˆ·ç ”ç©¶å·¥å…·
         - é¢„æœŸ3ä¸ªæœˆåè§æ•ˆï¼Œææ•ˆ15%
      
      3ï¸âƒ£ ä¸­æœŸè§„åˆ’ï¼ˆ3-6æœˆï¼‰ï¼š
         - ç”³è¯·ç ”å‘é¢„ç®—å¢åŠ 30%
         - æ‹›è˜æ ¸å¿ƒç ”å‘äººæ‰
         - é¢„æœŸ6ä¸ªæœˆåè§æ•ˆï¼Œæ•´ä½“åˆ©æ¶¦ç‡æå‡3-5%
      
      **åœºæ™¯æ¨¡æ‹Ÿ**ï¼ˆå¦‚æœå…¨éƒ¨å®æ–½ï¼‰ï¼š
      - 6ä¸ªæœˆåç ”å‘æ•ˆèƒ½é¢„è®¡è¾¾åˆ° 1.58 (+26%)
      - äº§å“å†…åœ¨ä»·å€¼æå‡ 25%
      - æ•´ä½“åˆ©æ¶¦ç‡æå‡ 4.2%
      - æŠ•èµ„å›æ”¶æœŸï¼š8-10ä¸ªæœˆ
      
      æ‚¨æ˜¯å¦éœ€è¦æˆ‘è¿›ä¸€æ­¥å±•å¼€æŸä¸ªå…·ä½“å»ºè®®ï¼Œæˆ–è€…ç”Ÿæˆè¯¦ç»†çš„
      å®æ–½è®¡åˆ’ï¼Ÿ
```

### 4.3 æ··åˆæ¨¡å¼ï¼ˆæ™ºèƒ½è·¯ç”±ï¼‰

**ç‰¹ç‚¹**: æ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©å¤„ç†ç­–ç•¥

**å†³ç­–é€»è¾‘**:
```python
def determine_mode(question: str, context: Dict) -> str:
    features = extract_features(question)
    complexity = calculate_complexity(features)
    
    if complexity <= 3:
        return "simple_qa"  # ç®€å•é—®ç­”æ¨¡å¼
    elif complexity <= 7:
        # å°è¯•æœ¬åœ°å¤„ç†ï¼Œå¤±è´¥åˆ™å‡çº§
        result = try_local_processing(question)
        if result.confidence < 0.7:
            return "deep_research"  # å‡çº§åˆ°æ·±åº¦ç ”ç©¶
        return "simple_qa"
    else:
        return "deep_research"  # æ·±åº¦ç ”ç©¶æ¨¡å¼
```

---

## 5. æŠ€æœ¯å®ç°

### 5.1 Tool Serverå®ç°

```python
# backend/src/services/tool_server.py
from fastapi import FastAPI, HTTPException
from typing import Dict, Any, Callable
import asyncio
from redis import Redis
import hashlib
import json

class ToolServer:
    """AI Copilotå·¥å…·æœåŠ¡å™¨"""
    
    def __init__(self):
        self.tools: Dict[str, Callable] = {}
        self.cache = Redis(host='localhost', port=6379, db=0)
        self.app = FastAPI(title="AI Copilot Tool Server")
        
        # æ³¨å†Œæ‰€æœ‰å·¥å…·
        self._register_tools()
        
        # è®¾ç½®å¥åº·æ£€æŸ¥
        @self.app.get("/health")
        async def health_check():
            return {"status": "healthy", "tools_count": len(self.tools)}
    
    def _register_tools(self):
        """æ³¨å†Œæ‰€æœ‰å·¥å…·å‡½æ•°"""
        from .tools import (
            query_analysis_results,
            execute_marginal_analysis,
            optimize_weights,
            get_insights,
            search_knowledge_base,
            query_asset_data,
            query_capability_data,
            predict_trend,
            compare_benchmarks,
            generate_report,
            search_industry_data,
            read_research_report,
            analyze_correlation,
            simulate_scenario,
            recommend_optimization
        )
        
        # MVPé˜¶æ®µå·¥å…·
        self.register("query_analysis_results", query_analysis_results)
        self.register("execute_marginal_analysis", execute_marginal_analysis)
        self.register("optimize_weights", optimize_weights)
        self.register("get_insights", get_insights)
        self.register("search_knowledge_base", search_knowledge_base)
        
        # æ‰©å±•é˜¶æ®µå·¥å…·
        self.register("query_asset_data", query_asset_data)
        self.register("query_capability_data", query_capability_data)
        self.register("predict_trend", predict_trend)
        self.register("compare_benchmarks", compare_benchmarks)
        self.register("generate_report", generate_report)
        
        # å®Œæ•´é˜¶æ®µå·¥å…·
        self.register("search_industry_data", search_industry_data)
        self.register("read_research_report", read_research_report)
        self.register("analyze_correlation", analyze_correlation)
        self.register("simulate_scenario", simulate_scenario)
        self.register("recommend_optimization", recommend_optimization)
    
    def register(self, name: str, func: Callable):
        """æ³¨å†Œå·¥å…·å‡½æ•°"""
        self.tools[name] = func
        
        # åŠ¨æ€åˆ›å»ºFastAPIç«¯ç‚¹
        @self.app.post(f"/tools/{name}")
        async def tool_endpoint(params: Dict[str, Any]):
            return await self.call(name, params)
    
    async def call(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨å·¥å…·å‡½æ•°
        
        æ”¯æŒç¼“å­˜ã€é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•
        """
        if tool_name not in self.tools:
            raise HTTPException(status_code=404, detail=f"Tool '{tool_name}' not found")
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(tool_name, params)
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self.cache.get(cache_key)
        if cached_result:
            return json.loads(cached_result)
        
        # æ‰§è¡Œå·¥å…·
        try:
            result = await self.tools[tool_name](params)
            
            # ç¼“å­˜ç»“æœï¼ˆTTL 1å°æ—¶ï¼‰
            self.cache.setex(
                cache_key,
                3600,
                json.dumps(result, ensure_ascii=False)
            )
            
            return result
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))
    
    def _generate_cache_key(self, tool_name: str, params: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        param_str = json.dumps(params, sort_keys=True)
        hash_str = hashlib.md5(f"{tool_name}:{param_str}".encode()).hexdigest()
        return f"tool_cache:{tool_name}:{hash_str}"
```

### 5.2 Redisç¼“å­˜ç­–ç•¥

```python
# ç¼“å­˜ç­–ç•¥é…ç½®
CACHE_CONFIG = {
    # MVPé˜¶æ®µå·¥å…·
    "query_analysis_results": {
        "ttl": 3600,  # 1å°æ—¶
        "invalidate_on": ["new_analysis_created"]
    },
    "execute_marginal_analysis": {
        "ttl": 7200,  # 2å°æ—¶
        "invalidate_on": ["data_updated"]
    },
    "optimize_weights": {
        "ttl": 86400,  # 24å°æ—¶
        "invalidate_on": ["weights_manually_updated"]
    },
    "get_insights": {
        "ttl": 1800,  # 30åˆ†é’Ÿ
        "invalidate_on": ["new_analysis_created"]
    },
    "search_knowledge_base": {
        "ttl": 600,  # 10åˆ†é’Ÿ
        "invalidate_on": ["knowledge_base_updated"]
    },
    
    # å¤–éƒ¨APIè°ƒç”¨ï¼ˆæ›´é•¿ç¼“å­˜ï¼‰
    "search_industry_data": {
        "ttl": 604800,  # 7å¤©
        "invalidate_on": []
    },
    "read_research_report": {
        "ttl": 2592000,  # 30å¤©
        "invalidate_on": []
    }
}

# ç¼“å­˜å¤±æ•ˆè§¦å‘å™¨
class CacheInvalidator:
    def __init__(self, redis_client: Redis):
        self.redis = redis_client
    
    def invalidate_pattern(self, pattern: str):
        """ä½¿åŒ¹é…æ¨¡å¼çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ"""
        for key in self.redis.scan_iter(match=f"tool_cache:*{pattern}*"):
            self.redis.delete(key)
    
    def on_new_analysis_created(self, analysis_id: str):
        """æ–°åˆ†æåˆ›å»ºæ—¶çš„ç¼“å­˜å¤±æ•ˆ"""
        self.invalidate_pattern("query_analysis_results")
        self.invalidate_pattern("get_insights")
    
    def on_data_updated(self, data_type: str, month: str):
        """æ•°æ®æ›´æ–°æ—¶çš„ç¼“å­˜å¤±æ•ˆ"""
        self.invalidate_pattern(f"execute_marginal_analysis:*{month}*")
        self.invalidate_pattern(f"query_{data_type}_data:*{month}*")
```

### 5.3 vLLM Servingé…ç½®

```python
# æœ¬åœ°æ¨¡å‹éƒ¨ç½²é…ç½®
# docker-compose.yml
services:
  vllm-server:
    image: vllm/vllm-openai:latest
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    environment:
      - MODEL_NAME=Qwen/Qwen2.5-7B-Instruct
      - TENSOR_PARALLEL_SIZE=1
      - MAX_MODEL_LEN=8192
      - GPU_MEMORY_UTILIZATION=0.9
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      --model /models/Qwen2.5-7B-Instruct
      --served-model-name qwen2.5-7b
      --max-model-len 8192
      --tensor-parallel-size 1
```

```python
# æ¨¡å‹å®¢æˆ·ç«¯
# backend/src/services/llm_client.py
from openai import AsyncOpenAI

class LLMClient:
    def __init__(self, use_local: bool = True):
        if use_local:
            self.client = AsyncOpenAI(
                base_url="http://localhost:8000/v1",
                api_key="dummy"  # vLLMä¸éœ€è¦API key
            )
            self.model = "qwen2.5-7b"
        else:
            self.client = AsyncOpenAI(api_key=os.getenv("GEMINI_API_KEY"))
            self.model = "gemini-1.5-pro"
    
    async def generate(self, messages: list, **kwargs) -> str:
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            **kwargs
        )
        return response.choices[0].message.content
```

---

## 6. æˆæœ¬ä¼˜åŒ–ç­–ç•¥

### 6.1 æˆæœ¬ä¼°ç®—

#### 6.1.1 APIè°ƒç”¨æˆæœ¬ï¼ˆGemini 1.5 Proï¼‰

| åŠŸèƒ½ | æœˆè°ƒç”¨é‡ | å•æ¬¡Tokenæ¶ˆè€— | æœˆæˆæœ¬ï¼ˆUSDï¼‰ |
|-----|---------|-------------|-------------|
| ç®€å•é—®ç­”ï¼ˆæœ¬åœ°ï¼‰ | 10,000 | 0 | $0 |
| æ·±åº¦ç ”ç©¶ | 500 | 5,000 input + 2,000 output | $17.5 |
| æŠ¥å‘Šç”Ÿæˆ | 200 | 3,000 input + 5,000 output | $9.8 |
| æ´å¯Ÿç”Ÿæˆ | 1,000 | 2,000 input + 1,000 output | $10.5 |
| å¤–éƒ¨æœç´¢ | 300 | 1,000 input + 500 output | $1.8 |
| **æ€»è®¡** | **12,000** | - | **$39.6/æœˆ** |

#### 6.1.2 åŸºç¡€è®¾æ–½æˆæœ¬

| ç»„ä»¶ | é…ç½® | æœˆæˆæœ¬ï¼ˆUSDï¼‰ |
|-----|------|-------------|
| Google Cloud Run (Backend API) | 2 vCPU, 4GB RAM | $30 |
| Supabase PostgreSQL | Pro Plan | $25 |
| Redis Cloud | 1GB | $0 (å…è´¹å¥—é¤) |
| vLLM Server (å¯é€‰ï¼Œæœ¬åœ°éƒ¨ç½²) | 1x T4 GPU | $50-100 |
| **æ€»è®¡ï¼ˆæ— æœ¬åœ°GPUï¼‰** | - | **$94.6/æœˆ** |
| **æ€»è®¡ï¼ˆå«æœ¬åœ°GPUï¼‰** | - | **$144.6-194.6/æœˆ** |

### 6.2 ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

**ç›®æ ‡**: ç¼“å­˜å‘½ä¸­ç‡ > 70%

```python
# æ™ºèƒ½ç¼“å­˜é¢„çƒ­
class CacheWarmer:
    """ç¼“å­˜é¢„çƒ­æœåŠ¡"""
    
    async def warm_up_common_queries(self):
        """é¢„çƒ­å¸¸è§æŸ¥è¯¢"""
        common_patterns = [
            # æœ€è¿‘æœˆä»½çš„åˆ†æç»“æœ
            ("query_analysis_results", {"time_range": {"start_month": last_month}}),
            
            # æ ¸å¿ƒèµ„äº§/èƒ½åŠ›æ•°æ®
            ("query_asset_data", {"asset_types": "all", "month": current_month}),
            ("query_capability_data", {"capability_types": "all", "month": current_month}),
            
            # å¸¸è§æ´å¯Ÿ
            ("get_insights", {"insight_types": ["opportunity", "risk"], "limit": 10})
        ]
        
        for tool_name, params in common_patterns:
            await tool_server.call(tool_name, params)
    
    async def predict_and_cache(self):
        """åŸºäºç”¨æˆ·è¡Œä¸ºé¢„æµ‹å¹¶ç¼“å­˜"""
        # åˆ†æç”¨æˆ·æŸ¥è¯¢æ¨¡å¼
        user_patterns = analyze_user_query_patterns()
        
        # é¢„æµ‹å¯èƒ½çš„æŸ¥è¯¢
        predicted_queries = predict_next_queries(user_patterns)
        
        # æå‰æ‰§è¡Œå¹¶ç¼“å­˜
        for query in predicted_queries:
            await execute_and_cache(query)
```

### 6.3 æœ¬åœ°æ¨¡å‹ vs APIåˆ‡æ¢ç­–ç•¥

```python
class AdaptiveModelRouter:
    """è‡ªé€‚åº”æ¨¡å‹è·¯ç”±"""
    
    def __init__(self):
        self.local_model = LLMClient(use_local=True)
        self.api_model = LLMClient(use_local=False)
        self.fallback_threshold = 0.7  # ç½®ä¿¡åº¦é˜ˆå€¼
    
    async def route_with_fallback(self, messages: list) -> str:
        """
        å…ˆå°è¯•æœ¬åœ°æ¨¡å‹ï¼Œç½®ä¿¡åº¦ä¸è¶³æ—¶å›é€€åˆ°API
        """
        # 1. å°è¯•æœ¬åœ°æ¨¡å‹
        local_response = await self.local_model.generate(
            messages, 
            temperature=0.3,
            max_tokens=2000
        )
        
        # 2. è¯„ä¼°ç½®ä¿¡åº¦
        confidence = self.evaluate_confidence(local_response)
        
        # 3. å¦‚æœç½®ä¿¡åº¦ä¸è¶³ï¼Œä½¿ç”¨APIæ¨¡å‹
        if confidence < self.fallback_threshold:
            logger.info(f"æœ¬åœ°æ¨¡å‹ç½®ä¿¡åº¦ä¸è¶³ ({confidence:.2f})ï¼Œå›é€€åˆ°Gemini API")
            return await self.api_model.generate(messages)
        
        return local_response
    
    def evaluate_confidence(self, response: str) -> float:
        """
        è¯„ä¼°å“åº”çš„ç½®ä¿¡åº¦
        
        è€ƒè™‘å› ç´ :
        - å“åº”é•¿åº¦æ˜¯å¦åˆç†
        - æ˜¯å¦åŒ…å«ä¸ç¡®å®šæ€§è¡¨è¾¾ ("å¯èƒ½", "å¤§æ¦‚", "ä¸ç¡®å®š")
        - æ˜¯å¦åŒ…å«å…·ä½“æ•°æ®å’Œäº‹å®
        - æ˜¯å¦ç¬¦åˆé¢„æœŸæ ¼å¼
        """
        confidence = 1.0
        
        # é•¿åº¦æ£€æŸ¥
        if len(response) < 50:
            confidence *= 0.6
        
        # ä¸ç¡®å®šæ€§è¡¨è¾¾æ£€æŸ¥
        uncertain_phrases = ["å¯èƒ½", "å¤§æ¦‚", "ä¸å¤ªç¡®å®š", "æˆ–è®¸", "ä¹Ÿè®¸"]
        for phrase in uncertain_phrases:
            if phrase in response:
                confidence *= 0.8
        
        # æ•°æ®å’Œäº‹å®æ£€æŸ¥
        has_numbers = bool(re.search(r'\d+', response))
        has_specific_terms = bool(re.search(r'(èµ„äº§|èƒ½åŠ›|æ•ˆèƒ½|ä»·å€¼|ROI)', response))
        if not (has_numbers and has_specific_terms):
            confidence *= 0.7
        
        return confidence
```

### 6.4 Google Cloud Runéƒ¨ç½²ä¼˜åŒ–

```yaml
# cloudrun-service.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: qbm-ai-copilot
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "1"  # ä¿æŒ1ä¸ªå®ä¾‹çƒ­å¯åŠ¨
        autoscaling.knative.dev/maxScale: "10"
        autoscaling.knative.dev/target: "80"  # 80% CPUä½¿ç”¨ç‡æ—¶æ‰©å®¹
    spec:
      containers:
      - image: gcr.io/project-id/qbm-ai-copilot:latest
        resources:
          limits:
            memory: "2Gi"
            cpu: "2"
          requests:
            memory: "1Gi"
            cpu: "1"
        env:
        - name: USE_LOCAL_MODEL
          value: "false"  # Cloud Runä¸Šä¸éƒ¨ç½²æœ¬åœ°æ¨¡å‹
        - name: GEMINI_API_KEY
          valueFrom:
            secretKeyRef:
              name: gemini-api-key
              key: key
        - name: REDIS_URL
          value: "redis://redis-service:6379"
```

**æˆæœ¬ä¼˜åŒ–è¦ç‚¹**:
1. **æœ€å°å®ä¾‹æ•°è®¾ä¸º1**: é¿å…å†·å¯åŠ¨ï¼Œä¿è¯å“åº”é€Ÿåº¦
2. **æœ€å¤§å®ä¾‹æ•°è®¾ä¸º10**: æ§åˆ¶çªå‘æµé‡æˆæœ¬
3. **ç›®æ ‡CPUä½¿ç”¨ç‡80%**: å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
4. **ä»…ä½¿ç”¨Gemini API**: Cloud Runä¸Šä¸éƒ¨ç½²GPUï¼Œé™ä½æˆæœ¬

---

## 7. é›†æˆç¤ºä¾‹

### 7.1 Python SDKç¤ºä¾‹

```python
# qbm_ai_copilot_sdk.py
from typing import Dict, Any, List
import requests

class QBMCopilot:
    """QBM AI Copilot Python SDK"""
    
    def __init__(self, api_url: str, api_key: str):
        self.api_url = api_url
        self.api_key = api_key
        self.session_id = None
    
    def ask(self, question: str, mode: str = "auto") -> Dict[str, Any]:
        """
        å‘AI Copilotæé—®
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            mode: å¤„ç†æ¨¡å¼ "simple"/"deep"/"auto"
        
        Returns:
            å“åº”å­—å…¸
        """
        response = requests.post(
            f"{self.api_url}/api/v1/copilot/ask",
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={
                "question": question,
                "mode": mode,
                "session_id": self.session_id
            }
        )
        
        result = response.json()
        self.session_id = result.get("session_id")
        
        return result
    
    def execute_analysis(self, month: str, options: Dict = None) -> Dict:
        """æ‰§è¡Œè¾¹é™…å½±å“åˆ†æ"""
        return self._call_tool("execute_marginal_analysis", {
            "analysis_month": month,
            "options": options or {}
        })
    
    def optimize_weights(self, historical_months: int = 12) -> Dict:
        """ä¼˜åŒ–æƒé‡"""
        return self._call_tool("optimize_weights", {
            "historical_months": historical_months
        })
    
    def get_insights(self, time_range: Dict = None) -> List[Dict]:
        """è·å–æ´å¯Ÿ"""
        result = self._call_tool("get_insights", {
            "time_range": time_range or {}
        })
        return result.get("insights", [])
    
    def _call_tool(self, tool_name: str, params: Dict) -> Dict:
        """è°ƒç”¨å·¥å…·"""
        response = requests.post(
            f"{self.api_url}/api/v1/copilot/tools/{tool_name}",
            headers={"Authorization": f"Bearer {self.api_key}"},
            json=params
        )
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
copilot = QBMCopilot(
    api_url="https://qbm-api.example.com",
    api_key="your-api-key"
)

# ç®€å•é—®ç­”
response = copilot.ask("2024å¹´10æœˆçš„ç ”å‘èµ„äº§NPVæ˜¯å¤šå°‘ï¼Ÿ")
print(response["message"])

# æ‰§è¡Œåˆ†æ
analysis = copilot.execute_analysis("2024-10", {
    "use_historical_fitting": True,
    "generate_insights": True
})
print(f"ROI: {analysis['results']['åˆ©æ¶¦ä¸ROI']['ROI']}")

# è·å–æ´å¯Ÿ
insights = copilot.get_insights({"start_month": "2024-01", "end_month": "2024-10"})
for insight in insights:
    print(f"[{insight['priority']}] {insight['title']}")
```

### 7.2 REST APIè°ƒç”¨ç¤ºä¾‹

```bash
# 1. è®¤è¯
curl -X POST https://qbm-api.example.com/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@enterprise.com",
    "password": "password"
  }'

# å“åº”: { "access_token": "eyJ0...", "token_type": "bearer" }

# 2. æé—®
curl -X POST https://qbm-api.example.com/api/v1/copilot/ask \
  -H "Authorization: Bearer eyJ0..." \
  -H "Content-Type: application/json" \
  -d '{
    "question": "å¸®æˆ‘åˆ†æä¸€ä¸‹æœ€è¿‘3ä¸ªæœˆçš„ç ”å‘æ•ˆèƒ½è¶‹åŠ¿",
    "mode": "deep"
  }'

# 3. è°ƒç”¨å·¥å…·
curl -X POST https://qbm-api.example.com/api/v1/copilot/tools/execute_marginal_analysis \
  -H "Authorization: Bearer eyJ0..." \
  -H "Content-Type: application/json" \
  -d '{
    "analysis_month": "2024-10",
    "options": {
      "use_historical_fitting": true,
      "generate_insights": true
    }
  }'
```

### 7.3 Frontendé›†æˆä»£ç 

```typescript
// frontend/src/services/copilotService.ts
import axios from 'axios';

interface CopilotQuestion {
  question: string;
  mode?: 'simple' | 'deep' | 'auto';
  sessionId?: string;
}

interface CopilotResponse {
  success: boolean;
  message: string;
  data?: any;
  suggestions?: string[];
  sessionId: string;
}

class CopilotService {
  private baseURL: string;
  private sessionId: string | null = null;

  constructor() {
    this.baseURL = process.env.REACT_APP_API_URL || 'http://localhost:8000';
  }

  async ask(question: string, mode: string = 'auto'): Promise<CopilotResponse> {
    const response = await axios.post<CopilotResponse>(
      `${this.baseURL}/api/v1/copilot/ask`,
      {
        question,
        mode,
        session_id: this.sessionId
      }
    );

    // ä¿å­˜session IDä»¥æ”¯æŒå¤šè½®å¯¹è¯
    this.sessionId = response.data.sessionId;
    
    return response.data;
  }

  async callTool(toolName: string, params: any): Promise<any> {
    const response = await axios.post(
      `${this.baseURL}/api/v1/copilot/tools/${toolName}`,
      params
    );
    return response.data;
  }

  resetSession() {
    this.sessionId = null;
  }
}

export const copilotService = new CopilotService();
```

```typescript
// frontend/src/components/CopilotChat.tsx
import React, { useState } from 'react';
import { copilotService } from '../services/copilotService';

export const CopilotChat: React.FC = () => {
  const [messages, setMessages] = useState<Array<{role: string, content: string}>>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);

  const handleSend = async () => {
    if (!input.trim()) return;

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    setMessages(prev => [...prev, { role: 'user', content: input }]);
    setInput('');
    setLoading(true);

    try {
      // è°ƒç”¨AI Copilot
      const response = await copilotService.ask(input);
      
      // æ·»åŠ AIå“åº”
      setMessages(prev => [...prev, { 
        role: 'assistant', 
        content: response.message 
      }]);
    } catch (error) {
      console.error('Error calling copilot:', error);
      setMessages(prev => [...prev, { 
        role: 'assistant', 
        content: 'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ã€‚' 
      }]);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="copilot-chat">
      <div className="messages">
        {messages.map((msg, idx) => (
          <div key={idx} className={`message ${msg.role}`}>
            {msg.content}
          </div>
        ))}
        {loading && <div className="message assistant loading">æ€è€ƒä¸­...</div>}
      </div>
      
      <div className="input-area">
        <input
          type="text"
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && handleSend()}
          placeholder="é—®æˆ‘ä»»ä½•å…³äºè¾¹é™…å½±å“åˆ†æçš„é—®é¢˜..."
        />
        <button onClick={handleSend} disabled={loading}>
          å‘é€
        </button>
      </div>
    </div>
  );
};
```

### 7.4 Gradio UIç¤ºä¾‹

```python
# gradio_app.py
import gradio as gr
from qbm_ai_copilot_sdk import QBMCopilot

copilot = QBMCopilot(
    api_url="http://localhost:8000",
    api_key="your-api-key"
)

def chat(message, history):
    """èŠå¤©æ¥å£"""
    response = copilot.ask(message, mode="auto")
    return response["message"]

def execute_analysis(month, use_fitting, gen_insights):
    """æ‰§è¡Œåˆ†æ"""
    result = copilot.execute_analysis(month, {
        "use_historical_fitting": use_fitting,
        "generate_insights": gen_insights
    })
    
    # æ ¼å¼åŒ–è¾“å‡º
    output = f"""
    ### åˆ†æç»“æœ ({month})
    
    **ROI**: {result['results']['åˆ©æ¶¦ä¸ROI']['ROI']:.2f}
    **ç ”å‘æ•ˆèƒ½**: {result['results']['æ•ˆèƒ½æŒ‡æ ‡']['ç ”å‘æ•ˆèƒ½']['value']:.2f}
    **ç”Ÿäº§æ•ˆèƒ½**: {result['results']['æ•ˆèƒ½æŒ‡æ ‡']['ç”Ÿäº§æ•ˆèƒ½']['value']:.2f}
    
    ### ä¸»è¦æ´å¯Ÿ
    """
    
    if result['results'].get('insights'):
        for insight in result['results']['insights'][:3]:
            output += f"\n- [{insight['priority']}] {insight['title']}"
    
    return output

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="QBM AI Copilot") as demo:
    gr.Markdown("# ğŸ¤– QBMè¾¹é™…å½±å“åˆ†æ AI Copilot")
    
    with gr.Tab("ğŸ’¬ æ™ºèƒ½é—®ç­”"):
        chatbot = gr.Chatbot()
        msg = gr.Textbox(placeholder="é—®æˆ‘ä»»ä½•é—®é¢˜...")
        clear = gr.Button("æ¸…é™¤å¯¹è¯")
        
        msg.submit(chat, [msg, chatbot], [chatbot])
        clear.click(lambda: None, None, chatbot, queue=False)
    
    with gr.Tab("ğŸ“Š æ‰§è¡Œåˆ†æ"):
        with gr.Row():
            month_input = gr.Textbox(label="åˆ†ææœˆä»½", value="2024-10")
            use_fitting = gr.Checkbox(label="ä½¿ç”¨å†å²æ•°æ®æ‹Ÿåˆ", value=True)
            gen_insights = gr.Checkbox(label="ç”Ÿæˆæ´å¯Ÿ", value=True)
        
        analyze_btn = gr.Button("æ‰§è¡Œåˆ†æ")
        analysis_output = gr.Markdown()
        
        analyze_btn.click(
            execute_analysis,
            inputs=[month_input, use_fitting, gen_insights],
            outputs=analysis_output
        )
    
    with gr.Tab("âš™ï¸ æƒé‡ä¼˜åŒ–"):
        hist_months = gr.Slider(minimum=3, maximum=24, value=12, step=1, 
                               label="å†å²æ•°æ®æœˆæ•°")
        optimize_btn = gr.Button("å¼€å§‹ä¼˜åŒ–")
        optimization_output = gr.JSON()
        
        optimize_btn.click(
            lambda months: copilot.optimize_weights(months),
            inputs=hist_months,
            outputs=optimization_output
        )

demo.launch()
```

---

## 8. éƒ¨ç½²å’Œè¿ç»´æŒ‡å—

### 8.1 æœ¬åœ°å¼€å‘ç¯å¢ƒéƒ¨ç½²

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/your-org/qbm-ai-system.git
cd qbm-ai-system

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envï¼Œå¡«å…¥API keysç­‰é…ç½®

# 3. å¯åŠ¨æœåŠ¡ï¼ˆä½¿ç”¨Docker Composeï¼‰
docker-compose up -d

# åŒ…æ‹¬çš„æœåŠ¡:
# - PostgreSQL (5432)
# - Redis (6379)
# - Backend API (8000)
# - Frontend (3000)
# - vLLM Server (8001ï¼Œå¯é€‰ï¼‰

# 4. åˆå§‹åŒ–æ•°æ®åº“
docker-compose exec backend python -m scripts.init_database

# 5. æµ‹è¯•AI Copilot
curl http://localhost:8000/api/v1/copilot/health
```

### 8.2 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆGoogle Cloud Runï¼‰

```bash
# 1. æ„å»ºDockeré•œåƒ
docker build -t gcr.io/your-project/qbm-backend:latest -f backend/Dockerfile .
docker build -t gcr.io/your-project/qbm-frontend:latest -f frontend/Dockerfile .

# 2. æ¨é€åˆ°Google Container Registry
docker push gcr.io/your-project/qbm-backend:latest
docker push gcr.io/your-project/qbm-frontend:latest

# 3. éƒ¨ç½²åˆ°Cloud Run
gcloud run deploy qbm-backend \
  --image gcr.io/your-project/qbm-backend:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --set-env-vars "DATABASE_URL=postgresql://...,GEMINI_API_KEY=..." \
  --memory 2Gi \
  --cpu 2 \
  --min-instances 1 \
  --max-instances 10

gcloud run deploy qbm-frontend \
  --image gcr.io/your-project/qbm-frontend:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

### 8.3 ç›‘æ§å’Œæ—¥å¿—

```python
# backend/src/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# å®šä¹‰æŒ‡æ ‡
copilot_requests_total = Counter(
    'copilot_requests_total',
    'Total AI Copilot requests',
    ['tool_name', 'mode', 'status']
)

copilot_request_duration = Histogram(
    'copilot_request_duration_seconds',
    'AI Copilot request duration',
    ['tool_name', 'mode']
)

copilot_cache_hits = Counter(
    'copilot_cache_hits_total',
    'Total cache hits',
    ['tool_name']
)

copilot_llm_api_calls = Counter(
    'copilot_llm_api_calls_total',
    'Total LLM API calls',
    ['model', 'status']
)

copilot_llm_tokens = Counter(
    'copilot_llm_tokens_total',
    'Total LLM tokens used',
    ['model', 'type']  # type: input/output
)

# ä½¿ç”¨ç¤ºä¾‹
@copilot_request_duration.time()
async def handle_copilot_request(tool_name: str, params: dict):
    start_time = time.time()
    
    try:
        result = await execute_tool(tool_name, params)
        copilot_requests_total.labels(
            tool_name=tool_name,
            mode=params.get('mode', 'auto'),
            status='success'
        ).inc()
        return result
        
    except Exception as e:
        copilot_requests_total.labels(
            tool_name=tool_name,
            mode=params.get('mode', 'auto'),
            status='error'
        ).inc()
        raise
```

**ç›‘æ§ä»ªè¡¨æ¿ï¼ˆGrafanaï¼‰**:
- è¯·æ±‚é‡å’ŒæˆåŠŸç‡
- å“åº”æ—¶é—´ï¼ˆP50, P95, P99ï¼‰
- ç¼“å­˜å‘½ä¸­ç‡
- APIè°ƒç”¨æ¬¡æ•°å’Œæˆæœ¬
- Tokenä½¿ç”¨é‡
- é”™è¯¯ç‡å’Œç±»å‹åˆ†å¸ƒ

### 8.4 æ•…éšœæ’æŸ¥

å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ:

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|-----|---------|---------|
| å“åº”è¶…æ—¶ | 1. æ•°æ®åº“æŸ¥è¯¢æ…¢<br>2. APIè°ƒç”¨è¶…æ—¶<br>3. ç¼“å­˜æœªå‘½ä¸­ | 1. ä¼˜åŒ–SQLæŸ¥è¯¢<br>2. å¢åŠ è¶…æ—¶æ—¶é—´<br>3. é¢„çƒ­ç¼“å­˜ |
| æˆæœ¬è¿‡é«˜ | 1. ç¼“å­˜å‘½ä¸­ç‡ä½<br>2. è¿‡åº¦ä½¿ç”¨Gemini API | 1. è°ƒæ•´ç¼“å­˜ç­–ç•¥<br>2. ä¼˜åŒ–è·¯ç”±é€»è¾‘ |
| å“åº”è´¨é‡å·® | 1. æœ¬åœ°æ¨¡å‹èƒ½åŠ›ä¸è¶³<br>2. Promptè®¾è®¡é—®é¢˜ | 1. å‡çº§åˆ°APIæ¨¡å‹<br>2. ä¼˜åŒ–Promptæ¨¡æ¿ |
| å¹¶å‘å¤„ç†æ…¢ | 1. å®ä¾‹æ•°ä¸è¶³<br>2. æ•°æ®åº“è¿æ¥æ± æ»¡ | 1. å¢åŠ max-instances<br>2. æ‰©å¤§è¿æ¥æ±  |

---

## 9. é™„å½•

### 9.1 æœ¯è¯­è¡¨

| æœ¯è¯­ | å®šä¹‰ |
|-----|------|
| Agent Loop | AIä»£ç†çš„æ ¸å¿ƒå¤„ç†å¾ªç¯ï¼šé—®é¢˜ç†è§£â†’å·¥å…·è§„åˆ’â†’æ‰§è¡Œâ†’åˆæˆ |
| Tool Server | å·¥å…·æœåŠ¡å™¨ï¼Œç®¡ç†å’Œæ‰§è¡Œæ‰€æœ‰å·¥å…·å‡½æ•° |
| æ™ºèƒ½è·¯ç”± | æ ¹æ®é—®é¢˜å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©å¤„ç†æ¨¡å¼ï¼ˆæœ¬åœ°/APIï¼‰ |
| æ··åˆéƒ¨ç½² | ç»“åˆæœ¬åœ°æ¨¡å‹å’Œäº‘APIçš„éƒ¨ç½²ç­–ç•¥ |
| vLLM | é«˜æ•ˆçš„å¤§æ¨¡å‹æ¨ç†æœåŠ¡å™¨ |
| Gemini 1.5 Pro | Googleçš„å¤§è¯­è¨€æ¨¡å‹API |

### 9.2 å‚è€ƒèµ„æ–™

- [PokeeResearchOSS GitHub](https://github.com/Pokee-AI/PokeeResearchOSS) - Agent Loopè®¾è®¡å‚è€ƒ
- [vLLM Documentation](https://docs.vllm.ai/) - æœ¬åœ°æ¨¡å‹éƒ¨ç½²
- [Gemini API Documentation](https://ai.google.dev/docs) - Google AI API
- [Google Cloud Run Documentation](https://cloud.google.com/run/docs) - éƒ¨ç½²æŒ‡å—

### 9.3 å˜æ›´æ—¥å¿—

| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´å†…å®¹ |
|-----|------|---------|
| v1.0.0 | 2025-10-23 | åˆå§‹ç‰ˆæœ¬ï¼ŒåŒ…å«MVP 5ä¸ªå·¥å…· |
| v1.1.0 | TBD | æ‰©å±•è‡³10ä¸ªå·¥å…· |
| v2.0.0 | TBD | å®Œæ•´15ä¸ªå·¥å…· + å¤–éƒ¨APIé›†æˆ |

---

## 10. ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### 10.1 Cursorçš„äº¤ä»˜ç‰© âœ…

- [x] AI Copiloté›†æˆæ–‡æ¡£ï¼ˆæœ¬æ–‡æ¡£ï¼‰
- [ ] Tool Serverå®ç°ä»£ç 
- [ ] Agent Loopå®ç°ä»£ç 
- [ ] æ™ºèƒ½è·¯ç”±å®ç°ä»£ç 
- [ ] å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

### 10.2 Lovableçš„å®æ–½ä»»åŠ¡ â³

**ä¼˜å…ˆçº§1ï¼ˆMVPé˜¶æ®µï¼‰**:
1. åˆ›å»ºAI CopilotèŠå¤©ç•Œé¢ç»„ä»¶
2. é›†æˆ5ä¸ªæ ¸å¿ƒå·¥å…·å‡½æ•°API
3. å®ç°ç®€å•é—®ç­”æ¨¡å¼UI
4. å®ç°ä¼šè¯å†å²ç®¡ç†

**ä¼˜å…ˆçº§2ï¼ˆæ‰©å±•é˜¶æ®µï¼‰**:
5. é›†æˆ10ä¸ªå·¥å…·å‡½æ•°ï¼ˆå«5ä¸ªæ–°å¢ï¼‰
6. å®ç°æ·±åº¦ç ”ç©¶æ¨¡å¼UIï¼ˆè¿›åº¦æ¡ã€å¤šæ­¥éª¤å±•ç¤ºï¼‰
7. å®ç°æŠ¥å‘Šç”Ÿæˆå’Œä¸‹è½½åŠŸèƒ½
8. æ·»åŠ æ´å¯Ÿå¯è§†åŒ–ç»„ä»¶

**ä¼˜å…ˆçº§3ï¼ˆå®Œæ•´é˜¶æ®µï¼‰**:
9. é›†æˆ15ä¸ªå®Œæ•´å·¥å…·å‡½æ•°
10. å®ç°å¤–éƒ¨æ•°æ®æœç´¢UI
11. æ·»åŠ åœºæ™¯æ¨¡æ‹Ÿäº¤äº’ç•Œé¢
12. ä¼˜åŒ–å»ºè®®çš„å¯è§†åŒ–å‘ˆç°

### 10.3 åä½œæ£€æŸ¥ç‚¹

- [ ] **æ£€æŸ¥ç‚¹1**: MVP 5ä¸ªå·¥å…·å‡½æ•°APIæµ‹è¯•é€šè¿‡ï¼ˆCursor â†’ Lovableï¼‰
- [ ] **æ£€æŸ¥ç‚¹2**: èŠå¤©ç•Œé¢é›†æˆå®Œæˆå¹¶è”è°ƒï¼ˆLovable â†’ Cursorï¼‰
- [ ] **æ£€æŸ¥ç‚¹3**: æ‰©å±•é˜¶æ®µ10ä¸ªå·¥å…·å…¨éƒ¨é›†æˆï¼ˆLovableï¼‰
- [ ] **æ£€æŸ¥ç‚¹4**: å®Œæ•´15ä¸ªå·¥å…·ä¸Šçº¿å¹¶æ€§èƒ½ä¼˜åŒ–ï¼ˆCursor + Lovableï¼‰

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å·²å®Œæˆï¼Œç­‰å¾…Lovableå®æ–½

**é¢„è®¡äº¤ä»˜æ—¶é—´**:
- MVPé˜¶æ®µï¼ˆ5ä¸ªå·¥å…·ï¼‰: 2å‘¨
- æ‰©å±•é˜¶æ®µï¼ˆ10ä¸ªå·¥å…·ï¼‰: +2å‘¨
- å®Œæ•´é˜¶æ®µï¼ˆ15ä¸ªå·¥å…·ï¼‰: +3å‘¨
- **æ€»è®¡**: 7å‘¨

**è”ç³»æ–¹å¼**:
- CursoræŠ€æœ¯æ”¯æŒ: cursor-team@example.com
- Lovableå®æ–½å›¢é˜Ÿ: lovable-team@example.com


