# QBM AI System - æ€§èƒ½ç›‘æ§æŒ‡å—

## ğŸ“Š ç›‘æ§æ¦‚è§ˆ

QBM AI Systemæä¾›å…¨é¢çš„æ€§èƒ½ç›‘æ§å’Œè¿ç»´æ”¯æŒï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šé«˜æ•ˆè¿è¡Œã€‚

---

## ğŸ” ç›‘æ§æŒ‡æ ‡

### 1. ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡

#### 1.1 APIæ€§èƒ½
- **å“åº”æ—¶é—´**: å¹³å‡å“åº”æ—¶é—´ < 500ms
- **ååé‡**: æ¯ç§’è¯·æ±‚æ•° (RPS)
- **é”™è¯¯ç‡**: 4xx/5xxé”™è¯¯ç‡ < 1%
- **å¯ç”¨æ€§**: ç³»ç»Ÿå¯ç”¨æ€§ > 99.9%

#### 1.2 æ•°æ®åº“æ€§èƒ½
- **è¿æ¥æ•°**: æ´»è·ƒè¿æ¥æ•° < 80% æœ€å¤§è¿æ¥æ•°
- **æŸ¥è¯¢æ—¶é—´**: å¹³å‡æŸ¥è¯¢æ—¶é—´ < 100ms
- **æ…¢æŸ¥è¯¢**: æ…¢æŸ¥è¯¢æ•°é‡ < 5%
- **è¿æ¥æ± **: è¿æ¥æ± ä½¿ç”¨ç‡ < 80%

#### 1.3 ç¼“å­˜æ€§èƒ½
- **å‘½ä¸­ç‡**: Redisç¼“å­˜å‘½ä¸­ç‡ > 90%
- **å“åº”æ—¶é—´**: ç¼“å­˜æ“ä½œå“åº”æ—¶é—´ < 10ms
- **å†…å­˜ä½¿ç”¨**: Rediså†…å­˜ä½¿ç”¨ç‡ < 80%
- **é”®è¿‡æœŸ**: è¿‡æœŸé”®æ¸…ç†æ•ˆç‡

### 2. AIæ¨¡å‹æ€§èƒ½

#### 2.1 é¢„æµ‹å‡†ç¡®æ€§
- **å‡†ç¡®ç‡**: é¢„æµ‹å‡†ç¡®ç‡ > 80%
- **ç½®ä¿¡åº¦**: å¹³å‡ç½®ä¿¡åº¦ > 0.7
- **å¬å›ç‡**: æ¨¡å‹å¬å›ç‡ > 75%
- **F1åˆ†æ•°**: ç»¼åˆè¯„ä¼°åˆ†æ•° > 0.8

#### 2.2 æ¨¡å‹æ€§èƒ½
- **æ¨ç†æ—¶é—´**: å•æ¬¡é¢„æµ‹æ—¶é—´ < 2s
- **æ‰¹å¤„ç†**: æ‰¹å¤„ç†ååé‡
- **å†…å­˜ä½¿ç”¨**: æ¨¡å‹å†…å­˜å ç”¨
- **GPUä½¿ç”¨**: GPUåˆ©ç”¨ç‡ (å¦‚é€‚ç”¨)

---

## ğŸ› ï¸ ç›‘æ§å·¥å…·é…ç½®

### 1. æ—¥å¿—ç›‘æ§

#### 1.1 æ—¥å¿—çº§åˆ«é…ç½®
```python
# logging_config.py
import logging
import structlog

# é…ç½®æ—¥å¿—çº§åˆ«
LOG_LEVEL = "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# ç»“æ„åŒ–æ—¥å¿—
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)
```

#### 1.2 æ—¥å¿—æ–‡ä»¶é…ç½®
```python
# æ—¥å¿—æ–‡ä»¶è½®è½¬
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
        'detailed': {
            'format': '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d: %(message)s'
        }
    },
    'handlers': {
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/app.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
            'formatter': 'detailed'
        },
        'error_file': {
            'level': 'ERROR',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/error.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
            'formatter': 'detailed'
        },
        'console': {
            'level': 'DEBUG',
            'class': 'logging.StreamHandler',
            'formatter': 'standard'
        }
    },
    'loggers': {
        '': {
            'handlers': ['file', 'error_file', 'console'],
            'level': 'INFO',
            'propagate': False
        }
    }
}
```

### 2. æ€§èƒ½ç›‘æ§

#### 2.1 PrometheusæŒ‡æ ‡
```python
# monitoring.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time

# APIè¯·æ±‚æŒ‡æ ‡
REQUEST_COUNT = Counter('api_requests_total', 'Total API requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('api_request_duration_seconds', 'API request duration')
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Active database connections')

# AIæ¨¡å‹æŒ‡æ ‡
AI_PREDICTION_COUNT = Counter('ai_predictions_total', 'Total AI predictions', ['model', 'status'])
AI_PREDICTION_DURATION = Histogram('ai_prediction_duration_seconds', 'AI prediction duration')
AI_MODEL_ACCURACY = Gauge('ai_model_accuracy', 'AI model accuracy', ['model'])

# æ•°æ®åº“æŒ‡æ ‡
DB_QUERY_DURATION = Histogram('db_query_duration_seconds', 'Database query duration')
DB_CONNECTION_POOL = Gauge('db_connection_pool_size', 'Database connection pool size')

# ç¼“å­˜æŒ‡æ ‡
CACHE_HITS = Counter('cache_hits_total', 'Cache hits', ['cache_type'])
CACHE_MISSES = Counter('cache_misses_total', 'Cache misses', ['cache_type'])
CACHE_SIZE = Gauge('cache_size_bytes', 'Cache size in bytes', ['cache_type'])
```

#### 2.2 å¥åº·æ£€æŸ¥ç«¯ç‚¹
```python
# health_check.py
from fastapi import APIRouter, Depends
from sqlalchemy import text
import redis
import psutil

router = APIRouter()

@router.get("/health")
async def health_check():
    """åŸºç¡€å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }

@router.get("/health/detailed")
async def detailed_health_check(
    db: DatabaseService = Depends(get_database_service),
    redis_client: redis.Redis = Depends(get_redis_client)
):
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "checks": {}
    }
    
    # æ•°æ®åº“æ£€æŸ¥
    try:
        result = await db.execute_query("SELECT 1")
        health_status["checks"]["database"] = {
            "status": "healthy",
            "response_time": "< 10ms"
        }
    except Exception as e:
        health_status["checks"]["database"] = {
            "status": "unhealthy",
            "error": str(e)
        }
        health_status["status"] = "unhealthy"
    
    # Redisæ£€æŸ¥
    try:
        redis_client.ping()
        health_status["checks"]["redis"] = {
            "status": "healthy",
            "response_time": "< 5ms"
        }
    except Exception as e:
        health_status["checks"]["redis"] = {
            "status": "unhealthy",
            "error": str(e)
        }
        health_status["status"] = "unhealthy"
    
    # ç³»ç»Ÿèµ„æºæ£€æŸ¥
    cpu_percent = psutil.cpu_percent()
    memory_percent = psutil.virtual_memory().percent
    disk_percent = psutil.disk_usage('/').percent
    
    health_status["checks"]["system"] = {
        "cpu_usage": f"{cpu_percent}%",
        "memory_usage": f"{memory_percent}%",
        "disk_usage": f"{disk_percent}%",
        "status": "healthy" if cpu_percent < 80 and memory_percent < 80 and disk_percent < 90 else "warning"
    }
    
    return health_status
```

### 3. å‘Šè­¦é…ç½®

#### 3.1 å‘Šè­¦è§„åˆ™
```yaml
# alerting_rules.yml
groups:
- name: qbm_ai_system
  rules:
  - alert: HighErrorRate
    expr: rate(api_requests_total{status=~"5.."}[5m]) > 0.01
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors per second"
  
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }} seconds"
  
  - alert: DatabaseConnectionHigh
    expr: db_connection_pool_size / db_connection_pool_max > 0.8
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High database connection usage"
      description: "Database connection pool is {{ $value }}% full"
  
  - alert: LowCacheHitRate
    expr: rate(cache_hits_total[5m]) / (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m])) < 0.8
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Low cache hit rate"
      description: "Cache hit rate is {{ $value }}%"
  
  - alert: AIModelAccuracyLow
    expr: ai_model_accuracy < 0.7
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "AI model accuracy is low"
      description: "Model {{ $labels.model }} accuracy is {{ $value }}"
```

#### 3.2 å‘Šè­¦é€šçŸ¥
```python
# alerting.py
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import requests

class AlertManager:
    def __init__(self):
        self.smtp_server = "smtp.gmail.com"
        self.smtp_port = 587
        self.email = "alerts@company.com"
        self.password = "your_password"
        self.webhook_url = "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
    
    def send_email_alert(self, alert_data):
        """å‘é€é‚®ä»¶å‘Šè­¦"""
        msg = MIMEMultipart()
        msg['From'] = self.email
        msg['To'] = "admin@company.com"
        msg['Subject'] = f"QBM AI System Alert: {alert_data['alertname']}"
        
        body = f"""
        Alert: {alert_data['alertname']}
        Severity: {alert_data['severity']}
        Description: {alert_data['description']}
        Time: {alert_data['timestamp']}
        """
        msg.attach(MIMEText(body, 'plain'))
        
        server = smtplib.SMTP(self.smtp_server, self.smtp_port)
        server.starttls()
        server.login(self.email, self.password)
        server.send_message(msg)
        server.quit()
    
    def send_slack_alert(self, alert_data):
        """å‘é€Slackå‘Šè­¦"""
        payload = {
            "text": f"ğŸš¨ QBM AI System Alert",
            "attachments": [
                {
                    "color": "danger" if alert_data['severity'] == 'critical' else "warning",
                    "fields": [
                        {"title": "Alert", "value": alert_data['alertname'], "short": True},
                        {"title": "Severity", "value": alert_data['severity'], "short": True},
                        {"title": "Description", "value": alert_data['description'], "short": False}
                    ]
                }
            ]
        }
        requests.post(self.webhook_url, json=payload)
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åº“ä¼˜åŒ–

#### 1.1 ç´¢å¼•ä¼˜åŒ–
```sql
-- ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µåˆ›å»ºç´¢å¼•
CREATE INDEX idx_objectives_priority ON strategic_objectives(priority);
CREATE INDEX idx_metrics_type ON north_star_metrics(metric_type);
CREATE INDEX idx_okr_period ON okrs(period_start, period_end);
CREATE INDEX idx_decisions_status ON decision_requirements(status);

-- å¤åˆç´¢å¼•
CREATE INDEX idx_okr_objective_period ON okrs(strategic_objective_id, period_start);
CREATE INDEX idx_metrics_health ON north_star_metrics(health_score, last_updated);
```

#### 1.2 æŸ¥è¯¢ä¼˜åŒ–
```python
# ä½¿ç”¨è¿æ¥æŸ¥è¯¢å‡å°‘æ•°æ®åº“å¾€è¿”
async def get_okr_with_metrics(okr_id: str):
    query = """
    SELECT o.*, k.kr_name, k.target_value, k.current_value
    FROM okrs o
    LEFT JOIN key_results k ON o.id = k.okr_id
    WHERE o.id = :okr_id
    """
    return await db.execute_query(query, {"okr_id": okr_id})

# ä½¿ç”¨åˆ†é¡µæŸ¥è¯¢
async def get_objectives_paginated(page: int, size: int):
    offset = (page - 1) * size
    query = """
    SELECT * FROM strategic_objectives
    ORDER BY created_at DESC
    LIMIT :size OFFSET :offset
    """
    return await db.execute_query(query, {"size": size, "offset": offset})
```

### 2. ç¼“å­˜ä¼˜åŒ–

#### 2.1 Redisç¼“å­˜ç­–ç•¥
```python
# cache_strategies.py
import redis
import json
from typing import Any, Optional

class CacheManager:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
    
    async def get_or_set(self, key: str, fetch_func, ttl: int = 3600):
        """è·å–ç¼“å­˜æˆ–è®¾ç½®ç¼“å­˜"""
        cached = self.redis_client.get(key)
        if cached:
            return json.loads(cached)
        
        data = await fetch_func()
        self.redis_client.setex(key, ttl, json.dumps(data))
        return data
    
    def invalidate_pattern(self, pattern: str):
        """æ‰¹é‡åˆ é™¤ç¼“å­˜"""
        keys = self.redis_client.keys(pattern)
        if keys:
            self.redis_client.delete(*keys)

# ç¼“å­˜é…ç½®
CACHE_CONFIG = {
    "objectives": {"ttl": 3600, "pattern": "objectives:*"},
    "metrics": {"ttl": 1800, "pattern": "metrics:*"},
    "okrs": {"ttl": 1800, "pattern": "okrs:*"},
    "predictions": {"ttl": 300, "pattern": "predictions:*"}
}
```

### 3. AIæ¨¡å‹ä¼˜åŒ–

#### 3.1 æ¨¡å‹ç¼“å­˜
```python
# model_cache.py
from functools import lru_cache
import joblib

class ModelCache:
    def __init__(self):
        self.model_cache = {}
        self.prediction_cache = {}
    
    @lru_cache(maxsize=100)
    def get_model(self, model_name: str):
        """ç¼“å­˜æ¨¡å‹å®ä¾‹"""
        if model_name not in self.model_cache:
            self.model_cache[model_name] = joblib.load(f"models/{model_name}.pkl")
        return self.model_cache[model_name]
    
    def cache_prediction(self, key: str, prediction: Any, ttl: int = 300):
        """ç¼“å­˜é¢„æµ‹ç»“æœ"""
        self.prediction_cache[key] = {
            "prediction": prediction,
            "timestamp": time.time(),
            "ttl": ttl
        }
    
    def get_cached_prediction(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜çš„é¢„æµ‹ç»“æœ"""
        if key in self.prediction_cache:
            cached = self.prediction_cache[key]
            if time.time() - cached["timestamp"] < cached["ttl"]:
                return cached["prediction"]
            else:
                del self.prediction_cache[key]
        return None
```

#### 3.2 æ‰¹å¤„ç†ä¼˜åŒ–
```python
# batch_processing.py
import asyncio
from typing import List, Any

class BatchProcessor:
    def __init__(self, batch_size: int = 32):
        self.batch_size = batch_size
    
    async def process_predictions(self, data_list: List[Any]):
        """æ‰¹é‡å¤„ç†é¢„æµ‹"""
        results = []
        for i in range(0, len(data_list), self.batch_size):
            batch = data_list[i:i + self.batch_size]
            batch_results = await self._process_batch(batch)
            results.extend(batch_results)
        return results
    
    async def _process_batch(self, batch: List[Any]):
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        tasks = [self._predict_single(item) for item in batch]
        return await asyncio.gather(*tasks)
```

---

## ğŸš¨ æ•…éšœå¤„ç†

### 1. å¸¸è§é—®é¢˜è¯Šæ–­

#### 1.1 æ€§èƒ½é—®é¢˜
```bash
# æ£€æŸ¥ç³»ç»Ÿèµ„æº
top
htop
iostat -x 1

# æ£€æŸ¥æ•°æ®åº“æ€§èƒ½
SELECT * FROM pg_stat_activity;
SELECT * FROM pg_stat_database;

# æ£€æŸ¥Redisæ€§èƒ½
redis-cli info stats
redis-cli slowlog get 10
```

#### 1.2 é”™è¯¯æ’æŸ¥
```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/app.log
grep ERROR logs/app.log
grep WARNING logs/app.log

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
journalctl -u qbm-ai-system -f
dmesg | tail -20
```

### 2. è‡ªåŠ¨æ¢å¤

#### 2.1 æœåŠ¡é‡å¯
```python
# auto_recovery.py
import subprocess
import time
import requests

class AutoRecovery:
    def __init__(self):
        self.max_retries = 3
        self.retry_delay = 30
    
    async def check_service_health(self):
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        try:
            response = requests.get("http://localhost:8000/health", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    async def restart_service(self):
        """é‡å¯æœåŠ¡"""
        subprocess.run(["systemctl", "restart", "qbm-ai-system"])
        time.sleep(10)
    
    async def auto_recovery_loop(self):
        """è‡ªåŠ¨æ¢å¤å¾ªç¯"""
        while True:
            if not await self.check_service_health():
                for attempt in range(self.max_retries):
                    await self.restart_service()
                    if await self.check_service_health():
                        break
                    time.sleep(self.retry_delay)
            time.sleep(60)
```

---

## ğŸ“Š ç›‘æ§ä»ªè¡¨æ¿

### 1. Grafanaé…ç½®

#### 1.1 ä»ªè¡¨æ¿é…ç½®
```json
{
  "dashboard": {
    "title": "QBM AI System Monitoring",
    "panels": [
      {
        "title": "API Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(api_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(api_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "AI Model Accuracy",
        "type": "singlestat",
        "targets": [
          {
            "expr": "ai_model_accuracy",
            "legendFormat": "{{model}}"
          }
        ]
      }
    ]
  }
}
```

---

**é€šè¿‡å®Œå–„çš„ç›‘æ§ä½“ç³»ï¼Œç¡®ä¿QBM AI Systemç¨³å®šé«˜æ•ˆè¿è¡Œï¼** ğŸš€
