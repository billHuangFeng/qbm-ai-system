# BMOS AI ç®—æ³•è½¬æ¢è®¾è®¡æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°å¦‚ä½•å°† FastAPI Python ç®—æ³•è½¬æ¢ä¸º Supabase Edge Functions (Deno/TypeScript) å®ç°ã€‚

## ğŸ¯ æ ¸å¿ƒç®—æ³•æ¸…å•

### Algorithm 1: æ–‡æ¡£æ ¼å¼è¯†åˆ« âœ… 
**çŠ¶æ€**: å·²å®ç°  
**ä½ç½®**: `supabase/functions/_shared/format-detector.ts`

#### ç®—æ³•æè¿°
è‡ªåŠ¨è¯†åˆ«6ç§å•æ®æ ¼å¼ç±»å‹:
1. **æ ¼å¼1**: å¤šè¡Œæ˜ç»†å¯¹åº”é‡å¤å•æ®å¤´
2. **æ ¼å¼2**: å¤šè¡Œæ˜ç»†ä½†åªæœ‰ç¬¬ä¸€è¡Œæœ‰å•æ®å¤´
3. **æ ¼å¼3**: å•æ®å¤´å’Œæ˜ç»†åˆ†ç¦»
4. **æ ¼å¼4**: åªæœ‰å•æ®å¤´è®°å½•
5. **æ ¼å¼5**: åªæœ‰æ˜ç»†è®°å½•
6. **æ ¼å¼6**: çº¯å•æ®å¤´è®°å½•

#### å®ç°è¦ç‚¹
```typescript
// 1. å­—æ®µæŸ¥æ‰¾ - æ”¯æŒå¤šç§åˆ«å
function findColumn(data: Record<string, any>[], possibleNames: string[]): string | null

// 2. æ ¼å¼æ£€æµ‹å‡½æ•°
function detectRepeatedHeader(data): [confidence, details]
function detectFirstRowHeader(data): [confidence, details]
function detectSeparateHeaderBody(data): [confidence, details]
function detectHeaderOnly(data): [confidence, details]
function detectDetailOnly(data): [confidence, details]
function detectPureHeader(data): [confidence, details]

// 3. ä¸»æ£€æµ‹é€»è¾‘
export async function detectFormat(data, metadata?): Promise<FormatDetectionResult>
```

#### è½¬æ¢è¦ç‚¹
- âœ… Python dict â†’ TypeScript Record<string, any>
- âœ… Python tuple â†’ TypeScript array [number, object]
- âœ… Python set â†’ TypeScript Set
- âœ… Python list comprehension â†’ TypeScript map/filter
- âœ… Python f-string â†’ TypeScript template literals

---

### Algorithm 2: æ•°æ®è´¨é‡æ£€æµ‹
**çŠ¶æ€**: å¾…å®ç°  
**ä½ç½®**: `supabase/functions/_shared/data-validator.ts`

#### ç®—æ³•æè¿°
æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜ï¼ŒåŒ…æ‹¬:
1. **å®Œæ•´æ€§æ£€æµ‹**: ç©ºå€¼æ¯”ä¾‹ã€å¿…å¡«å­—æ®µç¼ºå¤±
2. **å‡†ç¡®æ€§æ£€æµ‹**: æ•°æ®ç±»å‹éªŒè¯ã€æ ¼å¼éªŒè¯
3. **ä¸€è‡´æ€§æ£€æµ‹**: é‡å¤è®°å½•ã€æ•°æ®å…³è”æ€§
4. **å¼‚å¸¸å€¼æ£€æµ‹**: ç»Ÿè®¡ç¦»ç¾¤ç‚¹ã€ä¸šåŠ¡è§„åˆ™è¿å

#### Python åŸå‹
```python
def validate_data_quality(df: pd.DataFrame, rules: dict) -> QualityReport:
    """
    æ•°æ®è´¨é‡æ£€æµ‹
    
    Args:
        df: pandas DataFrame
        rules: éªŒè¯è§„åˆ™å­—å…¸
        
    Returns:
        QualityReport åŒ…å«è´¨é‡åˆ†æ•°å’Œé—®é¢˜åˆ—è¡¨
    """
    report = QualityReport()
    
    # 1. å®Œæ•´æ€§æ£€æµ‹
    null_ratio = df.isnull().sum() / len(df)
    report.completeness_score = 1.0 - null_ratio.mean()
    
    for field in rules.get('required_fields', []):
        if field not in df.columns:
            report.add_issue('MISSING_FIELD', field, severity='error')
        elif df[field].isnull().any():
            null_count = df[field].isnull().sum()
            report.add_issue('NULL_VALUE', field, 
                           affected_rows=null_count,
                           severity='error' if null_count/len(df) > 0.1 else 'warning')
    
    # 2. å‡†ç¡®æ€§æ£€æµ‹
    for field, dtype in rules.get('field_types', {}).items():
        if field in df.columns:
            try:
                df[field].astype(dtype)
            except:
                report.add_issue('TYPE_MISMATCH', field, severity='error')
    
    # 3. ä¸€è‡´æ€§æ£€æµ‹
    if rules.get('check_duplicates'):
        duplicates = df.duplicated()
        if duplicates.any():
            report.add_issue('DUPLICATE_ROWS', 
                           affected_rows=duplicates.sum(),
                           severity='warning')
    
    # 4. å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆé’ˆå¯¹æ•°å€¼å­—æ®µï¼‰
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        q1 = df[col].quantile(0.25)
        q3 = df[col].quantile(0.75)
        iqr = q3 - q1
        outliers = ((df[col] < q1 - 1.5*iqr) | (df[col] > q3 + 1.5*iqr)).sum()
        if outliers > 0:
            report.add_issue('OUTLIERS', col, 
                           affected_rows=outliers,
                           severity='info')
    
    # è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°
    report.calculate_overall_score()
    
    return report
```

#### TypeScript è½¬æ¢
```typescript
// supabase/functions/_shared/data-validator.ts

export interface ValidationRule {
  required_fields?: string[];
  field_types?: Record<string, string>;
  max_null_ratio?: number;
  check_duplicates?: boolean;
  outlier_detection?: boolean;
}

export interface QualityIssue {
  type: string;
  severity: 'error' | 'warning' | 'info';
  field?: string;
  description: string;
  affected_rows: number;
}

export interface QualityReport {
  overall_quality_score: number;
  completeness_score: number;
  accuracy_score: number;
  consistency_score: number;
  issues: QualityIssue[];
}

export async function validateDataQuality(
  data: Array<Record<string, any>>,
  rules: ValidationRule
): Promise<QualityReport> {
  const report: QualityReport = {
    overall_quality_score: 0,
    completeness_score: 0,
    accuracy_score: 0,
    consistency_score: 0,
    issues: []
  };
  
  if (data.length === 0) {
    return report;
  }
  
  const columns = Object.keys(data[0]);
  
  // 1. å®Œæ•´æ€§æ£€æµ‹
  report.completeness_score = calculateCompleteness(data, columns);
  checkRequiredFields(data, rules.required_fields || [], report);
  
  // 2. å‡†ç¡®æ€§æ£€æµ‹
  report.accuracy_score = checkFieldTypes(data, rules.field_types || {}, report);
  
  // 3. ä¸€è‡´æ€§æ£€æµ‹
  report.consistency_score = 1.0;
  if (rules.check_duplicates) {
    checkDuplicates(data, report);
  }
  
  // 4. å¼‚å¸¸å€¼æ£€æµ‹
  if (rules.outlier_detection) {
    detectOutliers(data, report);
  }
  
  // è®¡ç®—æ€»ä½“åˆ†æ•°
  report.overall_quality_score = (
    report.completeness_score +
    report.accuracy_score +
    report.consistency_score
  ) / 3;
  
  return report;
}

// è¾…åŠ©å‡½æ•°
function calculateCompleteness(
  data: Array<Record<string, any>>,
  columns: string[]
): number {
  let totalFields = data.length * columns.length;
  let nullFields = 0;
  
  for (const row of data) {
    for (const col of columns) {
      if (row[col] === null || row[col] === undefined || row[col] === '') {
        nullFields++;
      }
    }
  }
  
  return 1.0 - (nullFields / totalFields);
}

function checkRequiredFields(
  data: Array<Record<string, any>>,
  requiredFields: string[],
  report: QualityReport
): void {
  const columns = Object.keys(data[0]);
  
  for (const field of requiredFields) {
    if (!columns.includes(field)) {
      report.issues.push({
        type: 'MISSING_FIELD',
        severity: 'error',
        field,
        description: `å¿…å¡«å­—æ®µ "${field}" ä¸å­˜åœ¨`,
        affected_rows: 0
      });
      continue;
    }
    
    let nullCount = 0;
    for (const row of data) {
      if (row[field] === null || row[field] === undefined || row[field] === '') {
        nullCount++;
      }
    }
    
    if (nullCount > 0) {
      const nullRatio = nullCount / data.length;
      report.issues.push({
        type: 'NULL_VALUE',
        severity: nullRatio > 0.1 ? 'error' : 'warning',
        field,
        description: `å­—æ®µ "${field}" åŒ…å« ${nullCount} ä¸ªç©ºå€¼ (${(nullRatio * 100).toFixed(1)}%)`,
        affected_rows: nullCount
      });
    }
  }
}

function checkFieldTypes(
  data: Array<Record<string, any>>,
  fieldTypes: Record<string, string>,
  report: QualityReport
): number {
  let correctTypeFields = 0;
  let totalChecked = 0;
  
  for (const [field, expectedType] of Object.entries(fieldTypes)) {
    if (!data[0].hasOwnProperty(field)) {
      continue;
    }
    
    let typeErrors = 0;
    for (const row of data) {
      const value = row[field];
      if (value === null || value === undefined || value === '') {
        continue;
      }
      
      totalChecked++;
      const actualType = typeof value;
      
      // ç®€åŒ–çš„ç±»å‹æ£€æŸ¥
      if (expectedType === 'number' && actualType !== 'number') {
        if (isNaN(Number(value))) {
          typeErrors++;
        }
      } else if (expectedType === 'string' && actualType !== 'string') {
        typeErrors++;
      } else if (expectedType === 'boolean' && actualType !== 'boolean') {
        typeErrors++;
      } else {
        correctTypeFields++;
      }
    }
    
    if (typeErrors > 0) {
      report.issues.push({
        type: 'TYPE_MISMATCH',
        severity: 'error',
        field,
        description: `å­—æ®µ "${field}" ç±»å‹ä¸åŒ¹é…ï¼ŒæœŸæœ› ${expectedType}`,
        affected_rows: typeErrors
      });
    }
  }
  
  return totalChecked > 0 ? correctTypeFields / totalChecked : 1.0;
}

function checkDuplicates(
  data: Array<Record<string, any>>,
  report: QualityReport
): void {
  const seen = new Set<string>();
  let duplicates = 0;
  
  for (const row of data) {
    const key = JSON.stringify(row);
    if (seen.has(key)) {
      duplicates++;
    }
    seen.add(key);
  }
  
  if (duplicates > 0) {
    report.issues.push({
      type: 'DUPLICATE_ROWS',
      severity: 'warning',
      description: `æ£€æµ‹åˆ° ${duplicates} è¡Œé‡å¤æ•°æ®`,
      affected_rows: duplicates
    });
    report.consistency_score *= (1 - duplicates / data.length);
  }
}

function detectOutliers(
  data: Array<Record<string, any>>,
  report: QualityReport
): void {
  const columns = Object.keys(data[0]);
  
  for (const col of columns) {
    // æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å€¼åˆ—
    const values = data
      .map(row => row[col])
      .filter(v => v !== null && v !== undefined && typeof v === 'number' || !isNaN(Number(v)))
      .map(v => Number(v));
    
    if (values.length < 4) continue; // æ•°æ®å¤ªå°‘ï¼Œä¸è¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹
    
    // è®¡ç®—å››åˆ†ä½æ•°
    values.sort((a, b) => a - b);
    const q1 = quantile(values, 0.25);
    const q3 = quantile(values, 0.75);
    const iqr = q3 - q1;
    
    // æ£€æµ‹ç¦»ç¾¤ç‚¹
    let outlierCount = 0;
    for (const v of values) {
      if (v < q1 - 1.5 * iqr || v > q3 + 1.5 * iqr) {
        outlierCount++;
      }
    }
    
    if (outlierCount > 0) {
      report.issues.push({
        type: 'OUTLIERS',
        severity: 'info',
        field: col,
        description: `å­—æ®µ "${col}" æ£€æµ‹åˆ° ${outlierCount} ä¸ªå¼‚å¸¸å€¼`,
        affected_rows: outlierCount
      });
    }
  }
}

function quantile(arr: number[], q: number): number {
  const sorted = [...arr].sort((a, b) => a - b);
  const pos = (sorted.length - 1) * q;
  const base = Math.floor(pos);
  const rest = pos - base;
  
  if (sorted[base + 1] !== undefined) {
    return sorted[base] + rest * (sorted[base + 1] - sorted[base]);
  } else {
    return sorted[base];
  }
}
```

---

### Algorithm 3: ä¸»æ•°æ®åŒ¹é…
**çŠ¶æ€**: å¾…å®ç°  
**ä½ç½®**: `supabase/functions/_shared/master-data-matcher.ts`

#### ç®—æ³•æè¿°
ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…ç®—æ³•å°†å¯¼å…¥æ•°æ®ä¸ä¸»æ•°æ®è¡¨åŒ¹é…:
1. **ç²¾ç¡®åŒ¹é…**: å®Œå…¨ç›¸åŒçš„åç§°/ä»£ç 
2. **æ¨¡ç³ŠåŒ¹é…**: Levenshteinè·ç¦»ã€ç›¸ä¼¼åº¦è¯„åˆ†
3. **å¤šå€™é€‰æ¨è**: è¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„Nä¸ªå€™é€‰é¡¹
4. **ç¼“å­˜ä¼˜åŒ–**: ç¼“å­˜åŒ¹é…ç»“æœæé«˜æ€§èƒ½

#### Python åŸå‹
```python
from difflib import SequenceMatcher
import re

def calculate_similarity(str1: str, str2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ (0-1)"""
    # æ ‡å‡†åŒ–
    s1 = normalize_string(str1)
    s2 = normalize_string(str2)
    
    # ç²¾ç¡®åŒ¹é…
    if s1 == s2:
        return 1.0
    
    # ä½¿ç”¨ SequenceMatcher
    return SequenceMatcher(None, s1, s2).ratio()

def normalize_string(s: str) -> str:
    """å­—ç¬¦ä¸²æ ‡å‡†åŒ–"""
    s = s.strip().lower()
    # ç§»é™¤å¸¸è§åç¼€
    suffixes = ['æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸', 'é›†å›¢', 'ç§‘æŠ€', 'ç½‘ç»œ', 'ltd', 'inc', 'corp']
    for suffix in suffixes:
        s = s.replace(suffix, '')
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    s = re.sub(r'[^\w\s]', '', s)
    return s.strip()

def match_master_data(
    source_values: List[str],
    master_data: List[Dict],
    match_field: str,
    threshold: float = 0.8
) -> List[MatchResult]:
    """
    ä¸»æ•°æ®åŒ¹é…
    
    Args:
        source_values: å¾…åŒ¹é…çš„å€¼åˆ—è¡¨
        master_data: ä¸»æ•°æ®åˆ—è¡¨
        match_field: åŒ¹é…å­—æ®µå
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        
    Returns:
        åŒ¹é…ç»“æœåˆ—è¡¨
    """
    results = []
    
    for source_value in source_values:
        # ç²¾ç¡®åŒ¹é…
        exact_match = next(
            (item for item in master_data if item[match_field] == source_value),
            None
        )
        
        if exact_match:
            results.append({
                'source_value': source_value,
                'matched': True,
                'master_id': exact_match['id'],
                'master_name': exact_match[match_field],
                'confidence': 1.0
            })
            continue
        
        # æ¨¡ç³ŠåŒ¹é…
        candidates = []
        for item in master_data:
            similarity = calculate_similarity(source_value, item[match_field])
            if similarity >= threshold:
                candidates.append({
                    'id': item['id'],
                    'name': item[match_field],
                    'similarity': similarity
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        candidates.sort(key=lambda x: x['similarity'], reverse=True)
        
        if candidates:
            best_match = candidates[0]
            results.append({
                'source_value': source_value,
                'matched': True,
                'master_id': best_match['id'],
                'master_name': best_match['name'],
                'confidence': best_match['similarity'],
                'candidates': candidates[:5]  # è¿”å›top 5å€™é€‰
            })
        else:
            results.append({
                'source_value': source_value,
                'matched': False,
                'confidence': 0.0,
                'candidates': []
            })
    
    return results
```

#### TypeScript è½¬æ¢
```typescript
// supabase/functions/_shared/master-data-matcher.ts

export interface MatchCandidate {
  id: string;
  name: string;
  similarity: number;
}

export interface MatchResult {
  source_value: string;
  matched: boolean;
  master_id?: string;
  master_name?: string;
  confidence: number;
  candidates?: MatchCandidate[];
}

// Levenshtein è·ç¦»ç®—æ³•
function levenshteinDistance(str1: string, str2: string): number {
  const len1 = str1.length;
  const len2 = str2.length;
  const matrix: number[][] = [];
  
  for (let i = 0; i <= len1; i++) {
    matrix[i] = [i];
  }
  
  for (let j = 0; j <= len2; j++) {
    matrix[0][j] = j;
  }
  
  for (let i = 1; i <= len1; i++) {
    for (let j = 1; j <= len2; j++) {
      const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;
      matrix[i][j] = Math.min(
        matrix[i - 1][j] + 1,      // deletion
        matrix[i][j - 1] + 1,      // insertion
        matrix[i - 1][j - 1] + cost // substitution
      );
    }
  }
  
  return matrix[len1][len2];
}

// è®¡ç®—ç›¸ä¼¼åº¦
export function calculateSimilarity(str1: string, str2: string): number {
  const s1 = normalizeString(str1);
  const s2 = normalizeString(str2);
  
  // ç²¾ç¡®åŒ¹é…
  if (s1 === s2) {
    return 1.0;
  }
  
  // ä½¿ç”¨ Levenshtein è·ç¦»è®¡ç®—ç›¸ä¼¼åº¦
  const maxLen = Math.max(s1.length, s2.length);
  if (maxLen === 0) return 1.0;
  
  const distance = levenshteinDistance(s1, s2);
  return 1.0 - (distance / maxLen);
}

// å­—ç¬¦ä¸²æ ‡å‡†åŒ–
export function normalizeString(s: string): string {
  let normalized = s.trim().toLowerCase();
  
  // ç§»é™¤å¸¸è§åç¼€
  const suffixes = [
    'æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸', 'é›†å›¢', 'ç§‘æŠ€', 'ç½‘ç»œ', 
    'ltd', 'inc', 'corp', 'co.', 'limited'
  ];
  
  for (const suffix of suffixes) {
    normalized = normalized.replace(new RegExp(suffix + '$', 'i'), '');
  }
  
  // ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
  normalized = normalized.replace(/[^\u4e00-\u9fa5a-z0-9\s]/gi, '');
  
  return normalized.trim();
}

// ä¸»æ•°æ®åŒ¹é…
export async function matchMasterData(
  sourceValues: string[],
  masterData: Array<Record<string, any>>,
  matchField: string,
  threshold: number = 0.8
): Promise<MatchResult[]> {
  const results: MatchResult[] = [];
  
  for (const sourceValue of sourceValues) {
    // 1. ç²¾ç¡®åŒ¹é…
    const exactMatch = masterData.find(
      item => item[matchField] === sourceValue
    );
    
    if (exactMatch) {
      results.push({
        source_value: sourceValue,
        matched: true,
        master_id: exactMatch.id,
        master_name: exactMatch[matchField],
        confidence: 1.0
      });
      continue;
    }
    
    // 2. æ¨¡ç³ŠåŒ¹é…
    const candidates: MatchCandidate[] = [];
    
    for (const item of masterData) {
      const similarity = calculateSimilarity(
        sourceValue,
        item[matchField]
      );
      
      if (similarity >= threshold) {
        candidates.push({
          id: item.id,
          name: item[matchField],
          similarity
        });
      }
    }
    
    // æŒ‰ç›¸ä¼¼åº¦æ’åº
    candidates.sort((a, b) => b.similarity - a.similarity);
    
    if (candidates.length > 0) {
      const bestMatch = candidates[0];
      results.push({
        source_value: sourceValue,
        matched: true,
        master_id: bestMatch.id,
        master_name: bestMatch.name,
        confidence: bestMatch.similarity,
        candidates: candidates.slice(0, 5) // Top 5 å€™é€‰
      });
    } else {
      results.push({
        source_value: sourceValue,
        matched: false,
        confidence: 0.0,
        candidates: []
      });
    }
  }
  
  return results;
}
```

---

### Algorithm 4: å•æ®å¤´æå–
**çŠ¶æ€**: å¾…å®ç°  
**ä½ç½®**: `supabase/functions/_shared/header-extractor.ts`

#### ç®—æ³•æè¿°
æ ¹æ®è¯†åˆ«çš„æ ¼å¼ç±»å‹ï¼Œä»æ•°æ®ä¸­æå–å•æ®å¤´ä¿¡æ¯:
1. **æ ¼å¼1å¤„ç†**: å»é‡å¤çš„å•æ®å¤´
2. **æ ¼å¼2å¤„ç†**: æå–ç¬¬ä¸€è¡Œå•æ®å¤´
3. **æ ¼å¼3å¤„ç†**: åˆ†ç¦»å•æ®å¤´å’Œæ˜ç»†
4. **æ˜ç»†å…³è”**: å»ºç«‹å•æ®å¤´ä¸æ˜ç»†è¡Œçš„å…³è”å…³ç³»

#### Python åŸå‹
```python
def extract_headers(df: pd.DataFrame, format_type: str) -> List[DocumentHeader]:
    """
    æå–å•æ®å¤´
    
    Args:
        df: æ•°æ®DataFrame
        format_type: æ ¼å¼ç±»å‹
        
    Returns:
        å•æ®å¤´åˆ—è¡¨
    """
    headers = []
    
    if format_type == 'repeated_header':
        # æ ¼å¼1: æŒ‰å•æ®å·åˆ†ç»„ï¼Œæ¯ç»„å–ç¬¬ä¸€è¡Œä½œä¸ºå•æ®å¤´
        doc_col = find_column(df, ['å•æ®å·', 'document_number'])
        if doc_col:
            grouped = df.groupby(doc_col)
            for doc_num, group in grouped:
                header_row = group.iloc[0]
                headers.append({
                    'document_number': doc_num,
                    'document_date': header_row.get('å•æ®æ—¥æœŸ'),
                    'customer_name': header_row.get('å®¢æˆ·åç§°'),
                    'total_amount': group['é‡‘é¢'].sum() if 'é‡‘é¢' in group.columns else None,
                    'detail_row_indices': group.index.tolist()
                })
    
    elif format_type == 'first_row_header':
        # æ ¼å¼2: ç¬¬ä¸€è¡Œæ˜¯å•æ®å¤´
        header_row = df.iloc[0]
        headers.append({
            'document_number': header_row.get('å•æ®å·'),
            'document_date': header_row.get('å•æ®æ—¥æœŸ'),
            'customer_name': header_row.get('å®¢æˆ·åç§°'),
            'total_amount': df['é‡‘é¢'].sum() if 'é‡‘é¢' in df.columns else None,
            'detail_row_indices': list(range(len(df)))
        })
    
    elif format_type == 'separate_header_body':
        # æ ¼å¼3: å•æ®å¤´å’Œæ˜ç»†åˆ†ç¦»
        # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯å•æ®å¤´ï¼Œåç»­æ˜¯æ˜ç»†
        header_row = df.iloc[0]
        headers.append({
            'document_number': header_row.get('å•æ®å·'),
            'document_date': header_row.get('å•æ®æ—¥æœŸ'),
            'customer_name': header_row.get('å®¢æˆ·åç§°'),
            'total_amount': header_row.get('ä¸å«ç¨é‡‘é¢'),
            'detail_row_indices': list(range(1, len(df)))
        })
    
    return headers
```

#### TypeScript è½¬æ¢
```typescript
// supabase/functions/_shared/header-extractor.ts

export interface DocumentHeader {
  document_number: string;
  document_date?: string;
  customer_name?: string;
  total_amount?: number;
  detail_row_indices: number[];
  metadata?: Record<string, any>;
}

export async function extractHeaders(
  data: Array<Record<string, any>>,
  formatType: string
): Promise<DocumentHeader[]> {
  const headers: DocumentHeader[] = [];
  
  if (formatType === 'repeated_header') {
    // æ ¼å¼1: é‡å¤å•æ®å¤´ï¼ŒæŒ‰å•æ®å·åˆ†ç»„
    const docNumberCol = findColumn(data, ['å•æ®å·', 'document_number', 'è®¢å•å·']);
    
    if (!docNumberCol) {
      throw new Error('æœªæ‰¾åˆ°å•æ®å·å­—æ®µ');
    }
    
    // æŒ‰å•æ®å·åˆ†ç»„
    const grouped = new Map<string, number[]>();
    data.forEach((row, index) => {
      const docNum = row[docNumberCol];
      if (!grouped.has(docNum)) {
        grouped.set(docNum, []);
      }
      grouped.get(docNum)!.push(index);
    });
    
    // æå–æ¯ä¸ªå•æ®çš„å¤´ä¿¡æ¯
    for (const [docNum, indices] of grouped.entries()) {
      const firstRow = data[indices[0]];
      
      // è®¡ç®—æ€»é‡‘é¢
      let totalAmount = 0;
      const amountCol = findColumn(data, ['é‡‘é¢', 'amount', 'ä¸å«ç¨é‡‘é¢']);
      if (amountCol) {
        for (const idx of indices) {
          const amt = Number(data[idx][amountCol]) || 0;
          totalAmount += amt;
        }
      }
      
      headers.push({
        document_number: docNum,
        document_date: firstRow['å•æ®æ—¥æœŸ'] || firstRow['document_date'],
        customer_name: firstRow['å®¢æˆ·åç§°'] || firstRow['customer_name'],
        total_amount: totalAmount,
        detail_row_indices: indices
      });
    }
  } else if (formatType === 'first_row_header') {
    // æ ¼å¼2: åªæœ‰ç¬¬ä¸€è¡Œæœ‰å•æ®å¤´
    const firstRow = data[0];
    
    let totalAmount = 0;
    const amountCol = findColumn(data, ['é‡‘é¢', 'amount']);
    if (amountCol) {
      totalAmount = data.reduce((sum, row) => sum + (Number(row[amountCol]) || 0), 0);
    }
    
    headers.push({
      document_number: firstRow['å•æ®å·'] || firstRow['document_number'] || 'UNKNOWN',
      document_date: firstRow['å•æ®æ—¥æœŸ'] || firstRow['document_date'],
      customer_name: firstRow['å®¢æˆ·åç§°'] || firstRow['customer_name'],
      total_amount: totalAmount,
      detail_row_indices: Array.from({ length: data.length }, (_, i) => i)
    });
  } else if (formatType === 'separate_header_body') {
    // æ ¼å¼3: å•æ®å¤´å’Œæ˜ç»†åˆ†ç¦»
    const headerRow = data[0];
    
    headers.push({
      document_number: headerRow['å•æ®å·'] || headerRow['document_number'] || 'UNKNOWN',
      document_date: headerRow['å•æ®æ—¥æœŸ'] || headerRow['document_date'],
      customer_name: headerRow['å®¢æˆ·åç§°'] || headerRow['customer_name'],
      total_amount: Number(headerRow['ä¸å«ç¨é‡‘é¢'] || headerRow['total_amount']) || 0,
      detail_row_indices: Array.from({ length: data.length - 1 }, (_, i) => i + 1)
    });
  } else if (formatType === 'header_only') {
    // æ ¼å¼4: åªæœ‰å•æ®å¤´ï¼Œæ¯è¡Œä¸€ä¸ªå•æ®
    for (let i = 0; i < data.length; i++) {
      const row = data[i];
      headers.push({
        document_number: row['å•æ®å·'] || row['document_number'] || `DOC-${i + 1}`,
        document_date: row['å•æ®æ—¥æœŸ'] || row['document_date'],
        customer_name: row['å®¢æˆ·åç§°'] || row['customer_name'],
        total_amount: Number(row['é‡‘é¢'] || row['amount']) || 0,
        detail_row_indices: [i]
      });
    }
  }
  
  return headers;
}

// è¾…åŠ©å‡½æ•°ï¼šæŸ¥æ‰¾åˆ—å
function findColumn(data: Array<Record<string, any>>, possibleNames: string[]): string | null {
  if (data.length === 0) return null;
  
  const columns = Object.keys(data[0]);
  
  for (const colName of columns) {
    const normalized = colName.toLowerCase().trim();
    for (const possible of possibleNames) {
      if (normalized.includes(possible.toLowerCase()) || 
          possible.toLowerCase().includes(normalized)) {
        return colName;
      }
    }
  }
  
  return null;
}
```

---

## ğŸ”„ é€šç”¨è½¬æ¢æ¨¡å¼

### Pandas â†’ åŸç”ŸTypeScript

#### 1. DataFrameæ“ä½œ
```python
# Python
df.groupby('column')['amount'].sum()
df['field'].isnull().sum()
df.drop_duplicates()
```

```typescript
// TypeScript
// åˆ†ç»„æ±‚å’Œ
const grouped = new Map<string, number>();
data.forEach(row => {
  const key = row['column'];
  grouped.set(key, (grouped.get(key) || 0) + row['amount']);
});

// è®¡ç®—ç©ºå€¼
const nullCount = data.filter(row => 
  row['field'] === null || row['field'] === undefined || row['field'] === ''
).length;

// å»é‡
const unique = Array.from(
  new Map(data.map(row => [JSON.stringify(row), row])).values()
);
```

#### 2. æ•°å€¼è®¡ç®—
```python
# Python
import numpy as np
np.mean(df['column'])
np.quantile(df['column'], 0.75)
```

```typescript
// TypeScript
const mean = arr.reduce((sum, val) => sum + val, 0) / arr.length;

function quantile(arr: number[], q: number): number {
  const sorted = [...arr].sort((a, b) => a - b);
  const pos = (sorted.length - 1) * q;
  const base = Math.floor(pos);
  const rest = pos - base;
  return sorted[base] + rest * (sorted[base + 1] - sorted[base] || 0);
}
```

#### 3. å­—ç¬¦ä¸²å¤„ç†
```python
# Python
text.lower().strip()
re.sub(r'[^\w\s]', '', text)
```

```typescript
// TypeScript
text.toLowerCase().trim()
text.replace(/[^\w\s]/g, '')
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•
æ¯ä¸ªç®—æ³•æ¨¡å—ç‹¬ç«‹æµ‹è¯•ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ã€‚

### 2. é›†æˆæµ‹è¯•
åœ¨ Edge Functions ä¸­è°ƒç”¨ç®—æ³•ï¼ŒéªŒè¯ç«¯åˆ°ç«¯æµç¨‹ã€‚

### 3. æ€§èƒ½æµ‹è¯•
æµ‹è¯•å¤§æ•°æ®é‡ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼ˆ10ä¸‡è¡Œ+ï¼‰ã€‚

---

## ğŸ“š å‚è€ƒèµ„æº

- [Denoæ ‡å‡†åº“](https://deno.land/std)
- [TypeScriptæ–‡æ¡£](https://www.typescriptlang.org/docs/)
- [Levenshteinè·ç¦»ç®—æ³•](https://en.wikipedia.org/wiki/Levenshtein_distance)
- [æ•°æ®è´¨é‡æ£€æµ‹æœ€ä½³å®è·µ](https://www.talend.com/resources/what-is-data-quality/)
