# æ€§èƒ½ä¼˜åŒ–å®¡æŸ¥æŠ¥å‘Š

## æ¦‚è¿°

æœ¬æ–‡æ¡£å¯¹æ•°æ®å¯¼å…¥åŠŸèƒ½å’Œé‡‡è´­è®¢å•é¡µé¢è¿›è¡Œäº†å…¨é¢çš„æ€§èƒ½å®¡æŸ¥ï¼Œè¯†åˆ«äº†æ€§èƒ½ç“¶é¢ˆå’Œä¼˜åŒ–æœºä¼šã€‚

## ä¸€ã€æ•°æ®å¯¼å…¥åŠŸèƒ½æ€§èƒ½å®¡æŸ¥

### 1.1 å·²å®ç°çš„ä¼˜åŒ–

#### âœ… æ™ºèƒ½å­—æ®µæ˜ å°„å™¨ä¼˜åŒ–
- **å¤šå±‚ç¼“å­˜æœºåˆ¶**ï¼š
  - å†…å­˜ç¼“å­˜ï¼ˆè¿›ç¨‹å†…ç¼“å­˜ï¼‰
  - Redisç¼“å­˜ï¼ˆåˆ†å¸ƒå¼ç¼“å­˜ï¼‰
  - ç¼“å­˜TTLï¼š24å°æ—¶ï¼ˆè¡¨ç»“æ„å˜åŒ–ä¸é¢‘ç¹ï¼‰
- **å¹¶å‘æŸ¥è¯¢ä¼˜åŒ–**ï¼š
  - ä½¿ç”¨ `asyncio.gather()` å¹¶å‘è·å–è¡¨å­—æ®µå’Œä¸»æ•°æ®åŒ¹é…å­—æ®µ
  - å‡å°‘æ•°æ®åº“æŸ¥è¯¢ç­‰å¾…æ—¶é—´
- **ç¼“å­˜é¢„åŠ è½½**ï¼š
  - `preload_table_cache()` æ–¹æ³•æ”¯æŒé¢„åŠ è½½å¤šä¸ªè¡¨çš„ç¼“å­˜
  - `invalidate_table_cache()` æ–¹æ³•æ”¯æŒç¼“å­˜å¤±æ•ˆ

**ä»£ç ä½ç½®**: `backend/src/services/data_enhancement/intelligent_field_mapper.py`

#### âœ… æ•°æ®è´¨é‡æ£€æŸ¥ä¼˜åŒ–
- å¼‚æ­¥æ‰§è¡Œè´¨é‡æ£€æŸ¥
- åˆ†æ‰¹å¤„ç†å¤§é‡æ•°æ®

### 1.2 å‘ç°çš„æ€§èƒ½é—®é¢˜

#### âš ï¸ é—®é¢˜1: æ•°æ®å¯¼å…¥ETLåŒæ­¥å¤„ç†

**é—®é¢˜æè¿°**:
- `DataImportETL.process_data_import()` æ–¹æ³•æ˜¯åŒæ­¥çš„ï¼Œä½†å†…éƒ¨è°ƒç”¨äº†å¤šä¸ªå¼‚æ­¥æ–¹æ³•
- æ–‡ä»¶è¯»å–æ“ä½œï¼ˆç‰¹åˆ«æ˜¯å¤§æ–‡ä»¶ï¼‰å¯èƒ½é˜»å¡äº‹ä»¶å¾ªç¯

**å½±å“**:
- å¤§æ–‡ä»¶å¯¼å…¥æ—¶å“åº”ç¼“æ…¢
- å¯èƒ½é˜»å¡å…¶ä»–è¯·æ±‚å¤„ç†

**ä½ç½®**: `backend/src/services/data_import_etl.py:100-173`

**ä¼˜åŒ–å»ºè®®**:
```python
# å½“å‰ä»£ç ï¼ˆåŒæ­¥æ–¹æ³•è°ƒç”¨å¼‚æ­¥æ“ä½œï¼‰
async def process_data_import(...):
    raw_data = await self._read_source_data(...)  # å¯èƒ½é˜»å¡
    
# ä¼˜åŒ–å»ºè®®ï¼šä½¿ç”¨çº¿ç¨‹æ± å¤„ç†I/Oå¯†é›†å‹æ“ä½œ
async def process_data_import(...):
    loop = asyncio.get_event_loop()
    raw_data = await loop.run_in_executor(
        None, self._read_source_data_sync, ...
    )
```

#### âš ï¸ é—®é¢˜2: Excelæ–‡ä»¶è¯»å–æ€§èƒ½

**é—®é¢˜æè¿°**:
- `_read_excel_file()` ä½¿ç”¨ `openpyxl` è¯»å–æ•´ä¸ªæ–‡ä»¶åˆ°å†…å­˜
- å¯¹äºå¤§æ–‡ä»¶ï¼ˆ>100MBï¼‰ï¼Œå†…å­˜å ç”¨è¿‡é«˜
- æ‰€æœ‰å·¥ä½œè¡¨ä¸€æ¬¡æ€§åŠ è½½

**å½±å“**:
- å†…å­˜ä½¿ç”¨å³°å€¼é«˜
- å¤§æ–‡ä»¶å¯¼å…¥å¯èƒ½å¤±è´¥ï¼ˆå†…å­˜ä¸è¶³ï¼‰

**ä½ç½®**: `backend/src/services/data_import_etl.py:197-226`

**ä¼˜åŒ–å»ºè®®**:
```python
# ä¼˜åŒ–å»ºè®®1: ä½¿ç”¨æµå¼è¯»å–
async def _read_excel_file(self, file_path: str) -> Dict[str, Any]:
    # ä½¿ç”¨ openpyxl çš„ read_only æ¨¡å¼
    workbook = openpyxl.load_workbook(
        file_path, 
        data_only=True,
        read_only=True  # åªè¯»æ¨¡å¼ï¼Œå‡å°‘å†…å­˜å ç”¨
    )
    
    # æŒ‰éœ€è¯»å–å·¥ä½œè¡¨ï¼Œè€Œä¸æ˜¯å…¨éƒ¨åŠ è½½
    sheets_data = {}
    for sheet_name in workbook.sheetnames[:1]:  # åªè¯»å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
        sheet = workbook[sheet_name]
        # åˆ†æ‰¹è¯»å–æ•°æ®
        data = []
        for row in sheet.iter_rows(values_only=True, max_row=10000):  # é™åˆ¶è¡Œæ•°
            if any(cell is not None for cell in row):
                data.append(list(row))
        sheets_data[sheet_name] = {
            "data": data,
            "max_row": sheet.max_row,
            "max_column": sheet.max_column
        }
    
    return {"type": "excel", "file_path": file_path, "sheets": sheets_data}
```

#### âš ï¸ é—®é¢˜3: æ•°æ®è´¨é‡æ£€æŸ¥é‡å¤éå†

**é—®é¢˜æè¿°**:
- `DataQualityChecker` ä¸­çš„å„ä¸ªæ£€æŸ¥æ–¹æ³•ï¼ˆ`_check_missing_values`, `_check_duplicates` ç­‰ï¼‰ç‹¬ç«‹éå†æ•°æ®
- å¯¹äºå¤§æ•°æ®é›†ï¼Œå¤šæ¬¡éå†å¯¼è‡´æ€§èƒ½ä¸‹é™

**å½±å“**:
- è´¨é‡æ£€æŸ¥æ—¶é—´éšæ•°æ®é‡çº¿æ€§å¢é•¿
- ç”¨æˆ·ä½“éªŒå·®ï¼ˆç­‰å¾…æ—¶é—´é•¿ï¼‰

**ä½ç½®**: `backend/src/services/data_import_etl.py:978-1128`

**ä¼˜åŒ–å»ºè®®**:
```python
# ä¼˜åŒ–å»ºè®®ï¼šåˆå¹¶æ£€æŸ¥é€»è¾‘ï¼Œå•æ¬¡éå†å®Œæˆæ‰€æœ‰æ£€æŸ¥
async def check_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
    issues = []
    warnings = []
    
    # å•æ¬¡éå†ï¼ŒåŒæ—¶æ£€æŸ¥å¤šä¸ªé—®é¢˜
    if "rows" in data:
        rows = data["rows"]
        headers = data.get("headers", [])
        seen_rows = set()  # ç”¨äºé‡å¤æ£€æŸ¥
        
        for i, row in enumerate(rows):
            row_tuple = tuple(row)  # ç”¨äºé‡å¤æ£€æŸ¥
            
            # åŒæ—¶æ£€æŸ¥ç¼ºå¤±å€¼å’Œé‡å¤å€¼
            for j, cell in enumerate(row):
                # æ£€æŸ¥ç¼ºå¤±å€¼
                if cell is None or (isinstance(cell, str) and not cell.strip()):
                    if j < len(headers):
                        issues.append(f"ç¬¬ {i+1} è¡Œå­—æ®µ {headers[j]} å­˜åœ¨ç¼ºå¤±å€¼")
            
            # æ£€æŸ¥é‡å¤è¡Œ
            if row_tuple in seen_rows:
                issues.append(f"ç¬¬ {i+1} è¡Œä¸ä¹‹å‰çš„è¡Œå®Œå…¨é‡å¤")
            else:
                seen_rows.add(row_tuple)
    
    # ... å…¶ä»–æ£€æŸ¥é€»è¾‘
```

#### âš ï¸ é—®é¢˜4: å­—æ®µæ˜ å°„åº”ç”¨æ•ˆç‡

**é—®é¢˜æè¿°**:
- `FieldMapper.apply_mappings()` åœ¨åº”ç”¨æ˜ å°„æ—¶å¯¹æ¯ä¸€è¡Œæ•°æ®éƒ½è¿›è¡Œè½¬æ¢
- è½¬æ¢è§„åˆ™å¯èƒ½åŒ…å«æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼Œæ€§èƒ½å¼€é”€å¤§

**å½±å“**:
- å¤§æ–‡ä»¶å¯¼å…¥æ—¶æ˜ å°„åº”ç”¨è€—æ—¶
- ç”¨æˆ·ä½“éªŒå·®

**ä½ç½®**: `backend/src/services/data_import_etl.py:1130-1207`

**ä¼˜åŒ–å»ºè®®**:
```python
# ä¼˜åŒ–å»ºè®®ï¼šé¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ‰¹é‡å¤„ç†
async def apply_mappings(self, parsed_data, field_mappings):
    # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
    compiled_rules = {}
    for mapping in field_mappings:
        if mapping.transformation_rule and mapping.transformation_rule.startswith("regex:"):
            pattern = mapping.transformation_rule.split(":", 1)[1]
            compiled_rules[mapping.source_field] = re.compile(pattern)
    
    # æ‰¹é‡åº”ç”¨è½¬æ¢
    if "rows" in parsed_data:
        mapped_rows = []
        for row in parsed_data["rows"]:
            mapped_row = []
            for i, cell in enumerate(row):
                if i < len(headers) and headers[i] in mapping_dict:
                    mapping = mapping_dict[headers[i]]
                    # ä½¿ç”¨é¢„ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼
                    if mapping.source_field in compiled_rules:
                        transformed_cell = compiled_rules[mapping.source_field].sub(...)
                    else:
                        transformed_cell = await self._transform_cell(cell, mapping)
                    mapped_row.append(transformed_cell)
                else:
                    mapped_row.append(cell)
            mapped_rows.append(mapped_row)
```

### 1.3 ä¼˜åŒ–ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | é—®é¢˜ | å½±å“ | å·¥ä½œé‡ | é¢„æœŸæ”¶ç›Š |
|--------|------|------|--------|----------|
| ğŸ”´ é«˜ | Excelæ–‡ä»¶è¯»å–æ€§èƒ½ | å¤§æ–‡ä»¶å¯¼å…¥å¤±è´¥ | ä¸­ç­‰ | æ˜¾è‘—æå‡ |
| ğŸŸ¡ ä¸­ | æ•°æ®è´¨é‡æ£€æŸ¥é‡å¤éå† | æ£€æŸ¥æ—¶é—´è¿‡é•¿ | ä½ | ä¸­ç­‰æå‡ |
| ğŸŸ¡ ä¸­ | å­—æ®µæ˜ å°„åº”ç”¨æ•ˆç‡ | æ˜ å°„åº”ç”¨è€—æ—¶ | ä¸­ç­‰ | ä¸­ç­‰æå‡ |
| ğŸŸ¢ ä½ | ETLåŒæ­¥å¤„ç† | å¯èƒ½é˜»å¡ | é«˜ | ä½æå‡ |

## äºŒã€é‡‡è´­è®¢å•é¡µé¢æ€§èƒ½åˆ†æ

### 2.1 æ•°æ®åº“ç»“æ„

é‡‡è´­è®¢å•é‡‡ç”¨å¤´è¡¨-æ˜ç»†è¡¨ç»“æ„ï¼š
- `purchase_order_header`: è®¢å•å¤´è¡¨
- `purchase_order_line`: è®¢å•æ˜ç»†è¡¨ï¼ˆ1å¯¹å¤šå…³ç³»ï¼‰

**ç´¢å¼•**:
- `idx_purchase_order_header_tenant`: ç§Ÿæˆ·IDç´¢å¼•
- `idx_purchase_order_header_date`: è®¢å•æ—¥æœŸç´¢å¼•
- `idx_purchase_order_header_supplier`: ä¾›åº”å•†IDç´¢å¼•
- `idx_purchase_order_line_po`: è®¢å•IDç´¢å¼•ï¼ˆå¤–é”®ï¼‰

### 2.2 æ½œåœ¨æ€§èƒ½é—®é¢˜

#### âš ï¸ é—®é¢˜1: N+1æŸ¥è¯¢é—®é¢˜

**é—®é¢˜æè¿°**:
å¦‚æœé‡‡è´­è®¢å•åˆ—è¡¨APIå®ç°å¦‚ä¸‹ï¼š
```python
# ä¼ªä»£ç ç¤ºä¾‹
orders = db.query(purchase_order_header).all()  # æŸ¥è¯¢1æ¬¡
for order in orders:
    lines = db.query(purchase_order_line).filter_by(po_id=order.po_id).all()  # Næ¬¡æŸ¥è¯¢
    order.lines = lines
```

**å½±å“**:
- æŸ¥è¯¢100ä¸ªè®¢å•éœ€è¦æ‰§è¡Œ101æ¬¡æ•°æ®åº“æŸ¥è¯¢ï¼ˆ1+Nï¼‰
- å“åº”æ—¶é—´éšè®¢å•æ•°é‡çº¿æ€§å¢é•¿
- æ•°æ®åº“è´Ÿè½½é«˜

**è§£å†³æ–¹æ¡ˆ**:
ä½¿ç”¨ `PerformanceOptimizedService.batch_load_with_relations()` æ–¹æ³•ï¼š

```python
from backend.src.performance.optimization import PerformanceOptimizedService

# æ‰¹é‡åŠ è½½å…³è”æ•°æ®
optimizer = PerformanceOptimizedService(db_service)

result = await optimizer.batch_load_with_relations(
    main_table="purchase_order_header",
    relation_tables={
        "lines": {
            "table": "purchase_order_line",
            "foreign_key": "po_id",
            "local_key": "po_id"
        },
        "supplier": {
            "table": "dim_supplier",
            "foreign_key": "supplier_id",
            "local_key": "supplier_id"
        }
    },
    main_where="tenant_id = :tenant_id",
    main_params={"tenant_id": tenant_id},
    pagination=PaginationParams(page=1, size=20)
)
```

#### âš ï¸ é—®é¢˜2: ç¼ºå°‘åˆ†é¡µ

**é—®é¢˜æè¿°**:
å¦‚æœæ²¡æœ‰åˆ†é¡µï¼ŒæŸ¥è¯¢ä¼šåŠ è½½æ‰€æœ‰è®¢å•æ•°æ®ï¼š
```python
orders = db.query(purchase_order_header).all()  # åŠ è½½æ‰€æœ‰è®¢å•
```

**å½±å“**:
- æ•°æ®é‡å¤§æ—¶å†…å­˜å ç”¨é«˜
- å“åº”æ—¶é—´é•¿
- å‰ç«¯æ¸²æŸ“æ…¢

**è§£å†³æ–¹æ¡ˆ**:
ä½¿ç”¨ `PerformanceOptimizedService.paginated_query()` æ–¹æ³•ï¼š

```python
result = await optimizer.paginated_query(
    table="purchase_order_header",
    where_clause="tenant_id = :tenant_id",
    where_params={"tenant_id": tenant_id},
    order_by="po_date DESC",
    pagination=PaginationParams(page=1, size=20)
)
```

#### âš ï¸ é—®é¢˜3: ç¼ºå°‘ç¼“å­˜

**é—®é¢˜æè¿°**:
æ¯æ¬¡è¯·æ±‚éƒ½æŸ¥è¯¢æ•°æ®åº“ï¼Œæ²¡æœ‰ç¼“å­˜æœºåˆ¶ã€‚

**å½±å“**:
- ç›¸åŒæŸ¥è¯¢é‡å¤æ‰§è¡Œ
- æ•°æ®åº“è´Ÿè½½é«˜
- å“åº”æ—¶é—´ä¸ç¨³å®š

**è§£å†³æ–¹æ¡ˆ**:
```python
from backend.src.cache.redis_cache import RedisCache

cache = RedisCache()

# ç¼“å­˜æŸ¥è¯¢ç»“æœ
cache_key = f"purchase_orders:tenant:{tenant_id}:page:{page}:size:{size}"
cached_result = await cache.get('purchase_orders', cache_key)

if not cached_result:
    result = await optimizer.paginated_query(...)
    await cache.set('purchase_orders', result, cache_key, ttl=300)  # 5åˆ†é’Ÿç¼“å­˜
else:
    result = cached_result
```

#### âš ï¸ é—®é¢˜4: JOINæŸ¥è¯¢ä¼˜åŒ–

**é—®é¢˜æè¿°**:
å¦‚æœä½¿ç”¨JOINæŸ¥è¯¢ï¼Œéœ€è¦ç¡®ä¿ï¼š
1. JOINå­—æ®µæœ‰ç´¢å¼•
2. åªæŸ¥è¯¢éœ€è¦çš„å­—æ®µ
3. é¿å…SELECT *

**ä¼˜åŒ–å»ºè®®**:
```sql
-- ä¼˜åŒ–å‰ï¼ˆå¯èƒ½æ€§èƒ½å·®ï¼‰
SELECT * 
FROM purchase_order_header poh
LEFT JOIN purchase_order_line pol ON poh.po_id = pol.po_id
LEFT JOIN dim_supplier ds ON poh.supplier_id = ds.supplier_id
WHERE poh.tenant_id = :tenant_id

-- ä¼˜åŒ–åï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
SELECT 
    poh.po_id,
    poh.po_number,
    poh.po_date,
    poh.total_amount,
    poh.po_status,
    ds.supplier_name,
    COUNT(pol.line_id) as line_count
FROM purchase_order_header poh
LEFT JOIN dim_supplier ds ON poh.supplier_id = ds.supplier_id
LEFT JOIN purchase_order_line pol ON poh.po_id = pol.po_id
WHERE poh.tenant_id = :tenant_id
GROUP BY poh.po_id, poh.po_number, poh.po_date, poh.total_amount, poh.po_status, ds.supplier_name
ORDER BY poh.po_date DESC
LIMIT :limit OFFSET :offset
```

### 2.3 å‰ç«¯ä¼˜åŒ–å»ºè®®

#### âš ï¸ é—®é¢˜1: æ•°æ®åŠ è½½ç­–ç•¥

**é—®é¢˜æè¿°**:
å‰ç«¯å¯èƒ½ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰è®¢å•æ•°æ®ã€‚

**ä¼˜åŒ–å»ºè®®**:
1. **è™šæ‹Ÿæ»šåŠ¨**: åªæ¸²æŸ“å¯è§çš„è®¢å•é¡¹
2. **æ‡’åŠ è½½**: æŒ‰éœ€åŠ è½½è®¢å•æ˜ç»†
3. **åˆ†é¡µåŠ è½½**: ä½¿ç”¨åˆ†é¡µAPIï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½

#### âš ï¸ é—®é¢˜2: ç¼ºå°‘åŠ è½½çŠ¶æ€

**é—®é¢˜æè¿°**:
ç”¨æˆ·ä¸çŸ¥é“æ•°æ®æ­£åœ¨åŠ è½½ï¼Œä½“éªŒå·®ã€‚

**ä¼˜åŒ–å»ºè®®**:
æ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨ï¼ˆLoading spinnerï¼‰å’Œéª¨æ¶å±ï¼ˆSkeleton screenï¼‰ã€‚

### 2.4 ä¼˜åŒ–ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | é—®é¢˜ | å½±å“ | å·¥ä½œé‡ | é¢„æœŸæ”¶ç›Š |
|--------|------|------|--------|----------|
| ğŸ”´ é«˜ | N+1æŸ¥è¯¢é—®é¢˜ | å“åº”æ—¶é—´è¿‡é•¿ | ä¸­ç­‰ | æ˜¾è‘—æå‡ |
| ğŸ”´ é«˜ | ç¼ºå°‘åˆ†é¡µ | å†…å­˜å ç”¨é«˜ | ä½ | æ˜¾è‘—æå‡ |
| ğŸŸ¡ ä¸­ | ç¼ºå°‘ç¼“å­˜ | æ•°æ®åº“è´Ÿè½½é«˜ | ä½ | ä¸­ç­‰æå‡ |
| ğŸŸ¡ ä¸­ | JOINæŸ¥è¯¢ä¼˜åŒ– | æŸ¥è¯¢æ€§èƒ½ | ä¸­ç­‰ | ä¸­ç­‰æå‡ |
| ğŸŸ¢ ä½ | å‰ç«¯ä¼˜åŒ– | ç”¨æˆ·ä½“éªŒ | ä¸­ç­‰ | ä½æå‡ |

## ä¸‰ã€å®æ–½å»ºè®®

### 3.1 çŸ­æœŸä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰

1. **å®æ–½åˆ†é¡µæŸ¥è¯¢**ï¼š
   - ä¸ºé‡‡è´­è®¢å•åˆ—è¡¨APIæ·»åŠ åˆ†é¡µæ”¯æŒ
   - ä½¿ç”¨ `PerformanceOptimizedService.paginated_query()`

2. **ä¿®å¤N+1æŸ¥è¯¢**ï¼š
   - ä½¿ç”¨ `batch_load_with_relations()` æ‰¹é‡åŠ è½½å…³è”æ•°æ®
   - æ›´æ–°é‡‡è´­è®¢å•åˆ—è¡¨APIå®ç°

3. **æ·»åŠ ç¼“å­˜**ï¼š
   - ä¸ºé¢‘ç¹æŸ¥è¯¢çš„APIæ·»åŠ Redisç¼“å­˜
   - ç¼“å­˜TTLï¼š5-10åˆ†é’Ÿ

### 3.2 ä¸­æœŸä¼˜åŒ–ï¼ˆ2-4å‘¨ï¼‰

1. **ä¼˜åŒ–Excelæ–‡ä»¶è¯»å–**ï¼š
   - å®ç°æµå¼è¯»å–
   - ä½¿ç”¨ `read_only` æ¨¡å¼
   - åˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶

2. **ä¼˜åŒ–æ•°æ®è´¨é‡æ£€æŸ¥**ï¼š
   - åˆå¹¶æ£€æŸ¥é€»è¾‘ï¼Œå•æ¬¡éå†
   - å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ£€æŸ¥

3. **ä¼˜åŒ–å­—æ®µæ˜ å°„**ï¼š
   - é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
   - æ‰¹é‡å¤„ç†è½¬æ¢

### 3.3 é•¿æœŸä¼˜åŒ–ï¼ˆ1-2ä¸ªæœˆï¼‰

1. **å®æ–½åå°ä»»åŠ¡**ï¼š
   - å¤§æ–‡ä»¶å¯¼å…¥ä½¿ç”¨åå°ä»»åŠ¡å¤„ç†
   - ä½¿ç”¨ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå¦‚Celeryï¼‰

2. **æ•°æ®åº“ä¼˜åŒ–**ï¼š
   - åˆ†ææ…¢æŸ¥è¯¢æ—¥å¿—
   - ä¼˜åŒ–ç´¢å¼•ç­–ç•¥
   - è€ƒè™‘è¯»å†™åˆ†ç¦»

3. **ç›‘æ§å’Œå‘Šè­¦**ï¼š
   - æ·»åŠ æ€§èƒ½ç›‘æ§
   - è®¾ç½®æ…¢æŸ¥è¯¢å‘Šè­¦
   - ç›‘æ§APIå“åº”æ—¶é—´

## å››ã€æ€§èƒ½æŒ‡æ ‡ç›®æ ‡

### 4.1 æ•°æ®å¯¼å…¥æ€§èƒ½

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | ä¼˜åŒ–å |
|------|------|------|--------|
| å°æ–‡ä»¶ï¼ˆ<1MBï¼‰å¯¼å…¥æ—¶é—´ | ~2s | <1s | <0.5s |
| ä¸­ç­‰æ–‡ä»¶ï¼ˆ1-10MBï¼‰å¯¼å…¥æ—¶é—´ | ~10s | <5s | <3s |
| å¤§æ–‡ä»¶ï¼ˆ10-100MBï¼‰å¯¼å…¥æ—¶é—´ | ~60s | <30s | <20s |
| å†…å­˜å³°å€¼ï¼ˆ100MBæ–‡ä»¶ï¼‰ | ~500MB | <200MB | <150MB |

### 4.2 é‡‡è´­è®¢å•é¡µé¢æ€§èƒ½

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | ä¼˜åŒ–å |
|------|------|------|--------|
| åˆ—è¡¨åŠ è½½æ—¶é—´ï¼ˆ20æ¡ï¼‰ | ~2s | <1s | <0.5s |
| åˆ—è¡¨åŠ è½½æ—¶é—´ï¼ˆ100æ¡ï¼‰ | ~10s | <3s | <1s |
| æ•°æ®åº“æŸ¥è¯¢æ¬¡æ•° | 101æ¬¡ | 2-3æ¬¡ | 1-2æ¬¡ |
| APIå“åº”æ—¶é—´ï¼ˆP95ï¼‰ | ~2s | <1s | <0.5s |

## äº”ã€æ€»ç»“

### 5.1 å…³é”®å‘ç°

1. **æ•°æ®å¯¼å…¥åŠŸèƒ½**ï¼š
   - Excelæ–‡ä»¶è¯»å–æ˜¯ä¸»è¦ç“¶é¢ˆ
   - æ•°æ®è´¨é‡æ£€æŸ¥å¯ä»¥ä¼˜åŒ–
   - å­—æ®µæ˜ å°„åº”ç”¨æ•ˆç‡å¯ä»¥æå‡

2. **é‡‡è´­è®¢å•é¡µé¢**ï¼š
   - å¯èƒ½å­˜åœ¨N+1æŸ¥è¯¢é—®é¢˜
   - éœ€è¦æ·»åŠ åˆ†é¡µæ”¯æŒ
   - ç¼ºå°‘ç¼“å­˜æœºåˆ¶

### 5.2 æ¨èè¡ŒåŠ¨

1. **ç«‹å³å®æ–½**ï¼š
   - ä¸ºé‡‡è´­è®¢å•åˆ—è¡¨APIæ·»åŠ åˆ†é¡µå’Œæ‰¹é‡åŠ è½½
   - æ·»åŠ Redisç¼“å­˜

2. **çŸ­æœŸä¼˜åŒ–**ï¼š
   - ä¼˜åŒ–Excelæ–‡ä»¶è¯»å–
   - ä¼˜åŒ–æ•°æ®è´¨é‡æ£€æŸ¥

3. **é•¿æœŸè§„åˆ’**ï¼š
   - å®æ–½åå°ä»»åŠ¡å¤„ç†
   - å®Œå–„ç›‘æ§å’Œå‘Šè­¦

## å…­ã€ç›¸å…³æ–‡æ¡£

- [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](./performance/PERFORMANCE_OPTIMIZATION_GUIDE.md)
- [åç«¯æœåŠ¡çŠ¶æ€æ£€æŸ¥](./BACKEND_SERVICE_STATUS.md)
- [å¿«é€Ÿå¯åŠ¨åç«¯](./QUICK_START_BACKEND.md)

