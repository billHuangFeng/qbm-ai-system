# QBM AIç³»ç»Ÿ - å®Œæ•´å®æ–½æŒ‡å—

## ğŸ“‹ ç›®å½•
- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
- [æ ¸å¿ƒåŠŸèƒ½](#æ ¸å¿ƒåŠŸèƒ½)
- [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
- [APIæ–‡æ¡£](#apiæ–‡æ¡£)
- [ç®—æ³•è¯´æ˜](#ç®—æ³•è¯´æ˜)
- [æµ‹è¯•æŒ‡å—](#æµ‹è¯•æŒ‡å—)
- [è¿ç»´ç›‘æ§](#è¿ç»´ç›‘æ§)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

QBM AIç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäº"è¶Šç”¨è¶Šèªæ˜"ç†å¿µçš„æ™ºèƒ½ä¸šåŠ¡åˆ†æå¹³å°ï¼Œé€šè¿‡æœºå™¨å­¦ä¹ ç®—æ³•å’ŒæŒç»­å­¦ä¹ æœºåˆ¶ï¼Œä¸ºä¼ä¸šæä¾›æ·±åº¦çš„è¾¹é™…å½±å“åˆ†æå’Œå†³ç­–æ”¯æŒã€‚

### æ ¸å¿ƒç‰¹æ€§
- **è¾¹é™…å½±å“åˆ†æ**ï¼šååŒæ•ˆåº”ã€é˜ˆå€¼æ•ˆåº”ã€æ»åæ•ˆåº”åˆ†æ
- **åŠ¨æ€æƒé‡ä¼˜åŒ–**ï¼šåŸºäºå†å²æ•°æ®çš„æ™ºèƒ½æƒé‡è°ƒæ•´
- **ä¼ä¸šè®°å¿†ç³»ç»Ÿ**ï¼šå­¦ä¹ å’Œåº”ç”¨å†å²ç»éªŒ
- **ç®¡ç†è€…è¯„ä»·åé¦ˆ**ï¼šäººå·¥åé¦ˆä¸ç³»ç»Ÿå­¦ä¹ çš„ç»“åˆ
- **é¢„æµ‹å‡†ç¡®æ€§è·Ÿè¸ª**ï¼šæŒç»­ç›‘æ§å’Œä¼˜åŒ–æ¨¡å‹æ€§èƒ½

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å‰ç«¯ (Next.js) â”‚    â”‚  åç«¯ (FastAPI)  â”‚    â”‚  æ•°æ®åº“ (PostgreSQL) â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ - Reactç»„ä»¶     â”‚â—„â”€â”€â–ºâ”‚ - REST API      â”‚â—„â”€â”€â–ºâ”‚ - ä¸šåŠ¡æ•°æ®      â”‚
â”‚ - å›¾è¡¨å¯è§†åŒ–    â”‚    â”‚ - ç®—æ³•æœåŠ¡      â”‚    â”‚ - æ¨¡å‹å‚æ•°      â”‚
â”‚ - ç”¨æˆ·ç•Œé¢      â”‚    â”‚ - æ•°æ®å¤„ç†      â”‚    â”‚ - ä¼ä¸šè®°å¿†      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
         â”‚              â”‚  ç¼“å­˜ (Redis)   â”‚              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ - ä¼šè¯ç¼“å­˜      â”‚
                        â”‚ - æ¨¡å‹ç¼“å­˜      â”‚
                        â”‚ - ç»“æœç¼“å­˜      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŠ€æœ¯æ ˆ
- **å‰ç«¯**ï¼šNext.js 14, React 18, TypeScript, Tailwind CSS
- **åç«¯**ï¼šFastAPI, Python 3.11, Pydantic, SQLAlchemy
- **æ•°æ®åº“**ï¼šPostgreSQL 15, Redis 7
- **ç®—æ³•**ï¼šscikit-learn, XGBoost, LightGBM, scipy
- **éƒ¨ç½²**ï¼šDocker, Kubernetes, Nginx
- **ç›‘æ§**ï¼šPrometheus, Grafana

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### 1. è¾¹é™…å½±å“åˆ†æ
- **ååŒæ•ˆåº”åˆ†æ**ï¼šæ£€æµ‹ç‰¹å¾é—´çš„äº¤äº’ä½œç”¨
- **é˜ˆå€¼æ•ˆåº”åˆ†æ**ï¼šè¯†åˆ«å…³é”®é˜ˆå€¼ç‚¹
- **æ»åæ•ˆåº”åˆ†æ**ï¼šåˆ†ææ—¶é—´å»¶è¿Ÿå½±å“
- **é«˜çº§å…³ç³»åˆ†æ**ï¼šå‘ç°å¤æ‚çš„éçº¿æ€§å…³ç³»

### 2. åŠ¨æ€æƒé‡ç³»ç»Ÿ
- **æƒé‡è®¡ç®—**ï¼šåŸºäºç›¸å…³æ€§ã€é‡è¦æ€§ã€å›å½’ç³»æ•°
- **æƒé‡ä¼˜åŒ–**ï¼šæ¢¯åº¦ä¸‹é™ã€é—ä¼ ç®—æ³•ã€è´å¶æ–¯ä¼˜åŒ–
- **æƒé‡éªŒè¯**ï¼šäº¤å‰éªŒè¯ã€BootstrapéªŒè¯
- **æƒé‡ç›‘æ§**ï¼šæ¼‚ç§»æ£€æµ‹ã€ç¨³å®šæ€§ç›‘æ§

### 3. ä¼ä¸šè®°å¿†ç³»ç»Ÿ
- **è®°å¿†æå–**ï¼šä»åé¦ˆå’Œé”™è¯¯ä¸­å­¦ä¹ 
- **è®°å¿†å­˜å‚¨**ï¼šæ¨¡å¼ã€ç­–ç•¥ã€é˜ˆå€¼ã€ä¼˜åŒ–è§„åˆ™
- **è®°å¿†æ£€ç´¢**ï¼šåŸºäºTF-IDFå’Œä¸Šä¸‹æ–‡çš„ç›¸å…³æ€§åŒ¹é…
- **è®°å¿†åº”ç”¨**ï¼šè°ƒæ•´é¢„æµ‹å’Œå†³ç­–

### 4. ç®¡ç†è€…è¯„ä»·ç³»ç»Ÿ
- **è¯„ä»·æ”¶é›†**ï¼šç¡®è®¤ã€è°ƒæ•´ã€æ‹’ç»åé¦ˆ
- **è´¨é‡è¯„ä¼°**ï¼šå®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€ä¸€è‡´æ€§æ£€æŸ¥
- **å­¦ä¹ è®°å½•**ï¼šæ¨¡å¼è¯†åˆ«ã€åè§æ£€æµ‹
- **æ”¹è¿›å»ºè®®**ï¼šæµç¨‹æ”¹è¿›ã€å·¥å…·å¢å¼º

## ğŸ› ï¸ éƒ¨ç½²æŒ‡å—

### å¼€å‘ç¯å¢ƒéƒ¨ç½²

1. **å…‹éš†ä»“åº“**
```bash
git clone https://github.com/your-org/qbm-ai-system.git
cd qbm-ai-system
```

2. **ç¯å¢ƒé…ç½®**
```bash
cp env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œé…ç½®æ•°æ®åº“å’ŒRedisè¿æ¥ä¿¡æ¯
```

3. **Dockeréƒ¨ç½²**
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f backend
```

4. **éªŒè¯éƒ¨ç½²**
```bash
# æ£€æŸ¥APIå¥åº·çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥å‰ç«¯
curl http://localhost:3000
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

1. **Kuberneteséƒ¨ç½²**
```bash
# åº”ç”¨Kubernetesé…ç½®
kubectl apply -f kubernetes/qbm-ai-system.yaml

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
kubectl get pods -n qbm-ai-system

# æ£€æŸ¥æœåŠ¡
kubectl get services -n qbm-ai-system
```

2. **ç¯å¢ƒå˜é‡é…ç½®**
```bash
# åˆ›å»ºSecret
kubectl create secret generic qbm-secrets \
  --from-literal=POSTGRES_PASSWORD=your_password \
  --from-literal=REDIS_PASSWORD=your_redis_password \
  --from-literal=SECRET_KEY=your_secret_key \
  -n qbm-ai-system
```

3. **åŸŸåå’ŒSSLé…ç½®**
```bash
# é…ç½®Ingress
kubectl apply -f kubernetes/ingress.yaml

# é…ç½®SSLè¯ä¹¦
kubectl apply -f kubernetes/certificate.yaml
```

## ğŸ“š APIæ–‡æ¡£

### è®¤è¯
æ‰€æœ‰APIè¯·æ±‚éƒ½éœ€è¦JWTä»¤ç‰Œè®¤è¯ï¼š
```bash
curl -H "Authorization: Bearer <token>" \
     http://localhost:8000/api/v1/models/train/marginal-analysis
```

### æ ¸å¿ƒAPIç«¯ç‚¹

#### æ¨¡å‹è®­ç»ƒ
```http
POST /api/v1/models/train/marginal-analysis
Content-Type: application/json

{
  "model_name": "sales_analysis_model",
  "model_type": "marginal_analysis",
  "training_data": [...],
  "target_column": "revenue",
  "feature_columns": ["price", "quantity", "promotion"],
  "hyperparameters": {
    "n_estimators": 100,
    "max_depth": 10,
    "random_state": 42
  }
}
```

#### é¢„æµ‹æœåŠ¡
```http
POST /api/v1/models/predict
Content-Type: application/json

{
  "model_id": "model_123",
  "input_data": {
    "price": 100,
    "quantity": 50,
    "promotion": 0.1
  }
}
```

#### ä¼ä¸šè®°å¿†
```http
POST /api/v1/memory/extract/feedback
Content-Type: application/json

{
  "feedback_data": {
    "evaluation_id": "eval_123",
    "feedback_type": "confirmation",
    "feedback_content": "åˆ†æç»“æœå‡†ç¡®",
    "metrics": {
      "satisfaction_score": 0.9,
      "revenue_increase": 0.15
    }
  }
}
```

### å®Œæ•´APIæ–‡æ¡£
è®¿é—® `http://localhost:8000/docs` æŸ¥çœ‹Swagger UIæ–‡æ¡£ã€‚

## ğŸ§® ç®—æ³•è¯´æ˜

### ååŒæ•ˆåº”åˆ†æç®—æ³•

```python
class SynergyAnalysis:
    def detect_synergy_effects(self, X, y):
        """
        æ£€æµ‹ååŒæ•ˆåº”
        
        å‚æ•°:
        - X: ç‰¹å¾æ•°æ® (DataFrame)
        - y: ç›®æ ‡å˜é‡ (Series)
        
        è¿”å›:
        - ååŒæ•ˆåº”åˆ†æç»“æœ (dict)
        """
        results = {}
        
        # 1. ä¸¤ä¸¤äº¤äº’åˆ†æ
        results['pairwise_interactions'] = self._analyze_pairwise_interactions(X, y)
        
        # 2. å¤šé¡¹å¼äº¤äº’åˆ†æ
        results['polynomial_interactions'] = self._analyze_polynomial_interactions(X, y)
        
        # 3. éšæœºæ£®æ—äº¤äº’åˆ†æ
        results['random_forest_interactions'] = self._analyze_rf_interactions(X, y)
        
        # 4. Shapleyå€¼åˆ†æ
        results['shapley_values'] = self.calculate_shapley_values(X, y)
        
        return results
```

### é˜ˆå€¼åˆ†æç®—æ³•

```python
class ThresholdAnalysis:
    def detect_threshold_effects(self, X, y):
        """
        æ£€æµ‹é˜ˆå€¼æ•ˆåº”
        
        å‚æ•°:
        - X: ç‰¹å¾æ•°æ® (DataFrame)
        - y: ç›®æ ‡å˜é‡ (Series)
        
        è¿”å›:
        - é˜ˆå€¼æ•ˆåº”åˆ†æç»“æœ (dict)
        """
        results = {}
        
        # 1. å†³ç­–æ ‘é˜ˆå€¼æ£€æµ‹
        results['tree_thresholds'] = self._detect_tree_thresholds(X, y)
        
        # 2. åˆ†æ®µå›å½’åˆ†æ
        results['piecewise_regression'] = self._analyze_piecewise_regression(X, y)
        
        # 3. éšæœºæ£®æ—é˜ˆå€¼åˆ†æ
        results['random_forest_thresholds'] = self._analyze_rf_thresholds(X, y)
        
        return results
```

### åŠ¨æ€æƒé‡ç®—æ³•

```python
class DynamicWeights:
    def calculate_dynamic_weights(self, X, y, method='comprehensive'):
        """
        è®¡ç®—åŠ¨æ€æƒé‡
        
        å‚æ•°:
        - X: ç‰¹å¾æ•°æ® (DataFrame)
        - y: ç›®æ ‡å˜é‡ (Series)
        - method: è®¡ç®—æ–¹æ³• ('comprehensive', 'correlation', 'importance')
        
        è¿”å›:
        - åŠ¨æ€æƒé‡ç»“æœ (dict)
        """
        results = {}
        
        # 1. ç›¸å…³æ€§æƒé‡
        results['correlation_weights'] = self._calculate_correlation_weights(X, y)
        
        # 2. é‡è¦æ€§æƒé‡
        results['importance_weights'] = self._calculate_importance_weights(X, y)
        
        # 3. å›å½’æƒé‡
        results['regression_weights'] = self._calculate_regression_weights(X, y)
        
        # 4. æ—¶é—´åºåˆ—æƒé‡
        results['time_series_weights'] = self._calculate_time_series_weights(X, y)
        
        # 5. ç»¼åˆæƒé‡
        results['comprehensive_weights'] = self._calculate_comprehensive_weights(results)
        
        # 6. å½’ä¸€åŒ–æƒé‡
        results['normalized'] = self._normalize_weights(results['comprehensive_weights'])
        
        return results
```

## ğŸ§ª æµ‹è¯•æŒ‡å—

### è¿è¡Œæµ‹è¯•

1. **åç«¯æµ‹è¯•**
```bash
cd backend
pip install -r requirements.txt
pytest tests/ -v --cov=src --cov-report=html
```

2. **å‰ç«¯æµ‹è¯•**
```bash
cd frontend
npm install
npm run test
npm run test:coverage
```

3. **é›†æˆæµ‹è¯•**
```bash
# å¯åŠ¨æµ‹è¯•ç¯å¢ƒ
docker-compose -f docker-compose.test.yml up -d

# è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/integration/ -v
```

### æµ‹è¯•è¦†ç›–ç‡
- **åç«¯APIæµ‹è¯•**ï¼š95%+ è¦†ç›–ç‡
- **ç®—æ³•å•å…ƒæµ‹è¯•**ï¼š90%+ è¦†ç›–ç‡
- **å‰ç«¯ç»„ä»¶æµ‹è¯•**ï¼š85%+ è¦†ç›–ç‡
- **é›†æˆæµ‹è¯•**ï¼šå…³é”®æµç¨‹100%è¦†ç›–

## ğŸ“Š è¿ç»´ç›‘æ§

### ç›‘æ§æŒ‡æ ‡

1. **ç³»ç»ŸæŒ‡æ ‡**
- CPUä½¿ç”¨ç‡
- å†…å­˜ä½¿ç”¨ç‡
- ç£ç›˜ä½¿ç”¨ç‡
- ç½‘ç»œæµé‡

2. **åº”ç”¨æŒ‡æ ‡**
- APIå“åº”æ—¶é—´
- è¯·æ±‚æˆåŠŸç‡
- æ•°æ®åº“è¿æ¥æ•°
- ç¼“å­˜å‘½ä¸­ç‡

3. **ä¸šåŠ¡æŒ‡æ ‡**
- æ¨¡å‹è®­ç»ƒæ—¶é—´
- é¢„æµ‹å‡†ç¡®æ€§
- ç”¨æˆ·æ´»è·ƒåº¦
- æ•°æ®è´¨é‡åˆ†æ•°

### å‘Šè­¦é…ç½®

```yaml
# Prometheuså‘Šè­¦è§„åˆ™
groups:
- name: qbm-alerts
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      
  - alert: ModelAccuracyLow
    expr: model_accuracy_score < 0.7
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Model accuracy below threshold"
```

### æ—¥å¿—ç®¡ç†

```python
# æ—¥å¿—é…ç½®ç¤ºä¾‹
import logging
from logging.handlers import RotatingFileHandler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        RotatingFileHandler('logs/app.log', maxBytes=10*1024*1024, backupCount=5),
        logging.StreamHandler()
    ]
)
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®åº“è¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker-compose ps postgres

# æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—
docker-compose logs postgres

# æµ‹è¯•è¿æ¥
psql -h localhost -p 5432 -U postgres -d qbm_ai_system
```

2. **Redisè¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥RedisçŠ¶æ€
docker-compose ps redis

# æµ‹è¯•Redisè¿æ¥
redis-cli -h localhost -p 6379 ping
```

3. **APIå“åº”æ…¢**
```bash
# æ£€æŸ¥APIæ—¥å¿—
docker-compose logs backend

# æ£€æŸ¥æ•°æ®åº“æ€§èƒ½
SELECT * FROM pg_stat_activity;

# æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
redis-cli info stats | grep keyspace
```

4. **æ¨¡å‹è®­ç»ƒå¤±è´¥**
```bash
# æ£€æŸ¥è®­ç»ƒæ—¥å¿—
tail -f logs/model_training.log

# æ£€æŸ¥æ•°æ®è´¨é‡
python scripts/check_data_quality.py

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
docker stats
```

### æ€§èƒ½ä¼˜åŒ–

1. **æ•°æ®åº“ä¼˜åŒ–**
```sql
-- åˆ›å»ºç´¢å¼•
CREATE INDEX CONCURRENTLY idx_feature_analysis ON marginal_analysis_results(feature_name, analysis_date);

-- åˆ†æè¡¨ç»Ÿè®¡
ANALYZE marginal_analysis_results;

-- æ¸…ç†æ—§æ•°æ®
DELETE FROM prediction_accuracy_log WHERE prediction_date < NOW() - INTERVAL '90 days';
```

2. **ç¼“å­˜ä¼˜åŒ–**
```python
# Redisç¼“å­˜é…ç½®
CACHE_CONFIG = {
    'CACHE_TYPE': 'redis',
    'CACHE_REDIS_URL': 'redis://localhost:6379/0',
    'CACHE_DEFAULT_TIMEOUT': 3600,
    'CACHE_KEY_PREFIX': 'qbm:'
}
```

3. **APIä¼˜åŒ–**
```python
# å¼‚æ­¥å¤„ç†
from fastapi import BackgroundTasks

@app.post("/api/v1/models/train")
async def train_model(
    background_tasks: BackgroundTasks,
    model_data: ModelTrainingRequest
):
    # å¼‚æ­¥è®­ç»ƒæ¨¡å‹
    background_tasks.add_task(train_model_async, model_data)
    return {"message": "Training started"}
```

## ğŸ’¡ æœ€ä½³å®è·µ

### å¼€å‘æœ€ä½³å®è·µ

1. **ä»£ç è§„èŒƒ**
```python
# ä½¿ç”¨ç±»å‹æç¤º
def calculate_weights(X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:
    """è®¡ç®—ç‰¹å¾æƒé‡"""
    pass

# ä½¿ç”¨æ–‡æ¡£å­—ç¬¦ä¸²
def detect_synergy_effects(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, Any]:
    """
    æ£€æµ‹ç‰¹å¾é—´çš„ååŒæ•ˆåº”
    
    Args:
        X: ç‰¹å¾æ•°æ®çŸ©é˜µ
        y: ç›®æ ‡å˜é‡
        
    Returns:
        ååŒæ•ˆåº”åˆ†æç»“æœ
        
    Raises:
        ValueError: å½“è¾“å…¥æ•°æ®æ— æ•ˆæ—¶
    """
    pass
```

2. **é”™è¯¯å¤„ç†**
```python
try:
    result = model.predict(X)
except ModelNotFoundError:
    logger.error(f"Model {model_id} not found")
    raise HTTPException(status_code=404, detail="Model not found")
except PredictionError as e:
    logger.error(f"Prediction failed: {e}")
    raise HTTPException(status_code=500, detail="Prediction failed")
```

3. **æ•°æ®éªŒè¯**
```python
from pydantic import BaseModel, validator

class ModelTrainingRequest(BaseModel):
    model_name: str
    training_data: List[Dict[str, Any]]
    target_column: str
    
    @validator('model_name')
    def validate_model_name(cls, v):
        if not v or len(v) < 3:
            raise ValueError('Model name must be at least 3 characters')
        return v
```

### éƒ¨ç½²æœ€ä½³å®è·µ

1. **ç¯å¢ƒéš”ç¦»**
```bash
# å¼€å‘ç¯å¢ƒ
docker-compose -f docker-compose.dev.yml up -d

# æµ‹è¯•ç¯å¢ƒ
docker-compose -f docker-compose.test.yml up -d

# ç”Ÿäº§ç¯å¢ƒ
docker-compose -f docker-compose.prod.yml up -d
```

2. **å®‰å…¨é…ç½®**
```python
# å®‰å…¨å¤´é…ç½®
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://yourdomain.com"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["yourdomain.com", "*.yourdomain.com"]
)
```

3. **ç›‘æ§å’Œæ—¥å¿—**
```python
# ç»“æ„åŒ–æ—¥å¿—
import structlog

logger = structlog.get_logger()

logger.info(
    "Model training completed",
    model_id=model_id,
    training_time=training_time,
    accuracy=accuracy,
    user_id=user_id
)
```

### æ•°æ®ç®¡ç†æœ€ä½³å®è·µ

1. **æ•°æ®è´¨é‡æ£€æŸ¥**
```python
def validate_data_quality(df: pd.DataFrame) -> Dict[str, Any]:
    """éªŒè¯æ•°æ®è´¨é‡"""
    quality_report = {
        'total_rows': len(df),
        'missing_values': df.isnull().sum().to_dict(),
        'duplicate_rows': df.duplicated().sum(),
        'data_types': df.dtypes.to_dict(),
        'outliers': detect_outliers(df)
    }
    return quality_report
```

2. **æ•°æ®ç‰ˆæœ¬æ§åˆ¶**
```python
# æ•°æ®ç‰ˆæœ¬ç®¡ç†
class DataVersion:
    def __init__(self, version: str, checksum: str, created_at: datetime):
        self.version = version
        self.checksum = checksum
        self.created_at = created_at
    
    def save(self, data: pd.DataFrame):
        """ä¿å­˜æ•°æ®ç‰ˆæœ¬"""
        pass
```

3. **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†**
```python
# æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶
class ModelVersion:
    def __init__(self, model_id: str, version: str, performance: Dict[str, float]):
        self.model_id = model_id
        self.version = version
        self.performance = performance
        self.created_at = datetime.now()
    
    def compare_with(self, other: 'ModelVersion') -> Dict[str, Any]:
        """æ¯”è¾ƒæ¨¡å‹ç‰ˆæœ¬"""
        pass
```

## ğŸ“ æ”¯æŒå’Œè´¡çŒ®

### è·å–å¸®åŠ©
- **æ–‡æ¡£**ï¼šæŸ¥çœ‹å®Œæ•´æ–‡æ¡£å’ŒAPIå‚è€ƒ
- **Issues**ï¼šåœ¨GitHubä¸ŠæŠ¥å‘Šé—®é¢˜
- **è®¨è®º**ï¼šå‚ä¸ç¤¾åŒºè®¨è®º
- **é‚®ä»¶**ï¼šå‘é€é‚®ä»¶åˆ° support@qbm-ai-system.com

### è´¡çŒ®æŒ‡å—
1. Forkä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. åˆ›å»ºPull Request
5. ç­‰å¾…ä»£ç å®¡æŸ¥

### è®¸å¯è¯
æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ã€‚è¯¦è§LICENSEæ–‡ä»¶ã€‚

---

**QBM AIç³»ç»Ÿ** - è®©ä¸šåŠ¡åˆ†ææ›´æ™ºèƒ½ï¼Œè®©å†³ç­–æ›´ç²¾å‡†ï¼


